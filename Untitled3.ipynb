{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('FALL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['TIME','SL','EEG','BP','HR','CIRCLUATION']]\n",
    "y=df['FALL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.reshape(-1,1), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "y_train_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(30, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(30, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1a3078a7b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Dense(30, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1a30765be0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.layers.core.Dense at 0x1a30761c88>,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Dense(64, activation='relu', input_shape=(6,)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12286 samples, validate on 4096 samples\n",
      "Epoch 1/1000\n",
      "12286/12286 [==============================] - 0s 8us/sample - loss: 5.0787 - acc: 0.0246 - val_loss: 5.4490 - val_acc: 0.0342\n",
      "Epoch 2/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 5.0988 - acc: 0.0360 - val_loss: 5.5291 - val_acc: 0.0217\n",
      "Epoch 3/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 5.1983 - acc: 0.0180 - val_loss: 5.6593 - val_acc: 0.0183\n",
      "Epoch 4/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 5.3126 - acc: 0.0145 - val_loss: 5.7570 - val_acc: 0.0239\n",
      "Epoch 5/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 5.4206 - acc: 0.0176 - val_loss: 5.8881 - val_acc: 0.0095\n",
      "Epoch 6/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 5.5672 - acc: 0.0092 - val_loss: 6.0908 - val_acc: 0.0095\n",
      "Epoch 7/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 5.7643 - acc: 0.0100 - val_loss: 6.3363 - val_acc: 0.0125\n",
      "Epoch 8/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 5.9927 - acc: 0.0120 - val_loss: 6.5703 - val_acc: 0.0200\n",
      "Epoch 9/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 6.2521 - acc: 0.0154 - val_loss: 6.8454 - val_acc: 0.0176\n",
      "Epoch 10/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 6.5152 - acc: 0.0213 - val_loss: 7.2018 - val_acc: 0.0303\n",
      "Epoch 11/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 6.9123 - acc: 0.0465 - val_loss: 7.6615 - val_acc: 0.0549\n",
      "Epoch 12/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 7.3720 - acc: 0.0724 - val_loss: 8.2197 - val_acc: 0.0886\n",
      "Epoch 13/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 7.8525 - acc: 0.0868 - val_loss: 8.7574 - val_acc: 0.0911\n",
      "Epoch 14/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 8.4460 - acc: 0.0927 - val_loss: 9.4071 - val_acc: 0.1035\n",
      "Epoch 15/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 9.0250 - acc: 0.0958 - val_loss: 10.0454 - val_acc: 0.0776\n",
      "Epoch 16/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 9.6419 - acc: 0.0944 - val_loss: 10.7338 - val_acc: 0.0615\n",
      "Epoch 17/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 10.3022 - acc: 0.0920 - val_loss: 11.4630 - val_acc: 0.0852\n",
      "Epoch 18/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 10.9763 - acc: 0.0862 - val_loss: 12.2046 - val_acc: 0.0925\n",
      "Epoch 19/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 11.6610 - acc: 0.0820 - val_loss: 12.9372 - val_acc: 0.1040\n",
      "Epoch 20/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 12.3983 - acc: 0.0823 - val_loss: 13.7105 - val_acc: 0.0745\n",
      "Epoch 21/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 13.0373 - acc: 0.0738 - val_loss: 14.3671 - val_acc: 0.0708\n",
      "Epoch 22/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 13.7012 - acc: 0.0737 - val_loss: 15.1329 - val_acc: 0.0566\n",
      "Epoch 23/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 14.3984 - acc: 0.0703 - val_loss: 15.8875 - val_acc: 0.0603\n",
      "Epoch 24/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 15.0415 - acc: 0.0737 - val_loss: 16.5386 - val_acc: 0.0747\n",
      "Epoch 25/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 15.6211 - acc: 0.0683 - val_loss: 17.2037 - val_acc: 0.0718\n",
      "Epoch 26/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 16.2430 - acc: 0.0693 - val_loss: 17.8545 - val_acc: 0.1152\n",
      "Epoch 27/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 16.9107 - acc: 0.0710 - val_loss: 18.5618 - val_acc: 0.0540\n",
      "Epoch 28/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 17.4173 - acc: 0.0669 - val_loss: 19.0082 - val_acc: 0.0444\n",
      "Epoch 29/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 17.8047 - acc: 0.0643 - val_loss: 19.4839 - val_acc: 0.0430\n",
      "Epoch 30/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 18.2690 - acc: 0.0665 - val_loss: 19.9202 - val_acc: 0.0381\n",
      "Epoch 31/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 18.8295 - acc: 0.0668 - val_loss: 20.6061 - val_acc: 0.1377\n",
      "Epoch 32/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 19.0989 - acc: 0.0672 - val_loss: 20.7599 - val_acc: 0.0647\n",
      "Epoch 33/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 19.7180 - acc: 0.0641 - val_loss: 21.4971 - val_acc: 0.0688\n",
      "Epoch 34/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 20.2757 - acc: 0.0645 - val_loss: 21.9155 - val_acc: 0.0713\n",
      "Epoch 35/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 20.0474 - acc: 0.0596 - val_loss: 21.4192 - val_acc: 0.0435\n",
      "Epoch 36/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 20.0931 - acc: 0.0518 - val_loss: 21.8034 - val_acc: 0.0249\n",
      "Epoch 37/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 20.9320 - acc: 0.0542 - val_loss: 22.3882 - val_acc: 0.0107\n",
      "Epoch 38/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 21.0618 - acc: 0.0505 - val_loss: 21.9488 - val_acc: 0.0559\n",
      "Epoch 39/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 20.6211 - acc: 0.0403 - val_loss: 21.8977 - val_acc: 0.0603\n",
      "Epoch 40/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 20.2412 - acc: 0.0393 - val_loss: 20.8536 - val_acc: 9.7656e-04\n",
      "Epoch 41/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 19.4678 - acc: 0.0383 - val_loss: 20.3176 - val_acc: 0.2109\n",
      "Epoch 42/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 18.4677 - acc: 0.0452 - val_loss: 19.4679 - val_acc: 0.1887\n",
      "Epoch 43/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 18.0170 - acc: 0.0344 - val_loss: 19.1403 - val_acc: 0.0186\n",
      "Epoch 44/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 17.7492 - acc: 0.0534 - val_loss: 17.8121 - val_acc: 0.0706\n",
      "Epoch 45/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 16.2712 - acc: 0.0464 - val_loss: 16.5821 - val_acc: 0.0012\n",
      "Epoch 46/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 15.4518 - acc: 0.0368 - val_loss: 16.2681 - val_acc: 0.0044\n",
      "Epoch 47/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 14.8588 - acc: 0.0324 - val_loss: 14.8328 - val_acc: 0.2354\n",
      "Epoch 48/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 12.4047 - acc: 0.0485 - val_loss: 12.5151 - val_acc: 0.0237\n",
      "Epoch 49/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 12.2635 - acc: 0.0477 - val_loss: 12.8129 - val_acc: 0.0110\n",
      "Epoch 50/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 11.2014 - acc: 0.0393 - val_loss: 11.3114 - val_acc: 0.2427\n",
      "Epoch 51/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 9.4685 - acc: 0.0417 - val_loss: 7.8735 - val_acc: 0.0237\n",
      "Epoch 52/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 7.2395 - acc: 0.0549 - val_loss: 7.8694 - val_acc: 0.0049\n",
      "Epoch 53/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 7.1617 - acc: 0.0493 - val_loss: 7.7679 - val_acc: 0.0283\n",
      "Epoch 54/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 8.1564 - acc: 0.0531 - val_loss: 7.8582 - val_acc: 0.0256\n",
      "Epoch 55/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 8.2985 - acc: 0.0520 - val_loss: 8.6015 - val_acc: 0.0198\n",
      "Epoch 56/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 9.3201 - acc: 0.0432 - val_loss: 11.2975 - val_acc: 0.0195\n",
      "Epoch 57/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 9.1674 - acc: 0.0610 - val_loss: 8.7727 - val_acc: 0.0598\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 5us/sample - loss: 11.9923 - acc: 0.0514 - val_loss: 29.0826 - val_acc: 0.0200\n",
      "Epoch 59/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 26.5080 - acc: 0.0927 - val_loss: 22.8703 - val_acc: 0.0750\n",
      "Epoch 60/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 25.6394 - acc: 0.1078 - val_loss: 14.3991 - val_acc: 0.0710\n",
      "Epoch 61/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 17.5026 - acc: 0.0746 - val_loss: 15.4861 - val_acc: 0.0623\n",
      "Epoch 62/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 15.1583 - acc: 0.1066 - val_loss: 18.1480 - val_acc: 0.0671\n",
      "Epoch 63/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 18.3624 - acc: 0.1144 - val_loss: 25.2558 - val_acc: 0.0071\n",
      "Epoch 64/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 18.1243 - acc: 0.0900 - val_loss: 22.7092 - val_acc: 0.1138\n",
      "Epoch 65/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 19.9861 - acc: 0.1132 - val_loss: 18.3658 - val_acc: 0.1255\n",
      "Epoch 66/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 13.7959 - acc: 0.1120 - val_loss: 14.8714 - val_acc: 0.2361\n",
      "Epoch 67/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 15.4143 - acc: 0.1244 - val_loss: 15.8122 - val_acc: 0.0081\n",
      "Epoch 68/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 14.5839 - acc: 0.0921 - val_loss: 16.9390 - val_acc: 0.0049\n",
      "Epoch 69/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 15.3867 - acc: 0.0990 - val_loss: 15.2927 - val_acc: 0.1238\n",
      "Epoch 70/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 16.6618 - acc: 0.1100 - val_loss: 18.3878 - val_acc: 0.1162\n",
      "Epoch 71/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 16.9372 - acc: 0.1077 - val_loss: 15.4517 - val_acc: 0.0295\n",
      "Epoch 72/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 13.4951 - acc: 0.1168 - val_loss: 17.4166 - val_acc: 0.0139\n",
      "Epoch 73/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 14.8188 - acc: 0.1155 - val_loss: 15.4828 - val_acc: 0.0078\n",
      "Epoch 74/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 14.0632 - acc: 0.1073 - val_loss: 14.0891 - val_acc: 0.0044\n",
      "Epoch 75/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 13.3637 - acc: 0.1008 - val_loss: 18.1451 - val_acc: 0.0320\n",
      "Epoch 76/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 16.4945 - acc: 0.0975 - val_loss: 17.3867 - val_acc: 0.0088\n",
      "Epoch 77/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 20.4782 - acc: 0.1253 - val_loss: 24.2325 - val_acc: 0.0051\n",
      "Epoch 78/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 22.8081 - acc: 0.0844 - val_loss: 29.3884 - val_acc: 0.0017\n",
      "Epoch 79/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 23.9122 - acc: 0.0895 - val_loss: 22.3421 - val_acc: 0.0144\n",
      "Epoch 80/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 25.5402 - acc: 0.0976 - val_loss: 27.4648 - val_acc: 0.5823\n",
      "Epoch 81/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 23.5573 - acc: 0.1218 - val_loss: 24.4416 - val_acc: 0.0520\n",
      "Epoch 82/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 23.5403 - acc: 0.1077 - val_loss: 30.6131 - val_acc: 0.0034\n",
      "Epoch 83/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 28.4480 - acc: 0.0808 - val_loss: 25.2550 - val_acc: 0.0823\n",
      "Epoch 84/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 22.3052 - acc: 0.1139 - val_loss: 22.7561 - val_acc: 0.0266\n",
      "Epoch 85/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 26.2527 - acc: 0.0995 - val_loss: 35.9842 - val_acc: 0.0100\n",
      "Epoch 86/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 33.5631 - acc: 0.0869 - val_loss: 39.3331 - val_acc: 0.2046\n",
      "Epoch 87/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 32.5620 - acc: 0.1168 - val_loss: 34.9607 - val_acc: 9.7656e-04\n",
      "Epoch 88/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 29.0812 - acc: 0.0982 - val_loss: 29.7196 - val_acc: 0.0037\n",
      "Epoch 89/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 25.4670 - acc: 0.0987 - val_loss: 22.7418 - val_acc: 0.0166\n",
      "Epoch 90/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 25.6551 - acc: 0.0858 - val_loss: 32.0744 - val_acc: 0.0437\n",
      "Epoch 91/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 26.1326 - acc: 0.0879 - val_loss: 31.5143 - val_acc: 0.1086\n",
      "Epoch 92/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 27.7858 - acc: 0.0969 - val_loss: 18.1768 - val_acc: 0.6357\n",
      "Epoch 93/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 26.8594 - acc: 0.1096 - val_loss: 25.8751 - val_acc: 0.0564\n",
      "Epoch 94/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 27.2267 - acc: 0.1183 - val_loss: 30.5751 - val_acc: 0.0120\n",
      "Epoch 95/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 26.9547 - acc: 0.0936 - val_loss: 32.0998 - val_acc: 0.0317\n",
      "Epoch 96/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 31.1759 - acc: 0.1053 - val_loss: 22.9740 - val_acc: 0.2471\n",
      "Epoch 97/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 28.9053 - acc: 0.1299 - val_loss: 23.0054 - val_acc: 0.0139\n",
      "Epoch 98/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 32.3944 - acc: 0.0843 - val_loss: 20.7192 - val_acc: 0.3218\n",
      "Epoch 99/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 26.4658 - acc: 0.1125 - val_loss: 32.3512 - val_acc: 0.0037\n",
      "Epoch 100/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 31.0098 - acc: 0.1121 - val_loss: 35.7914 - val_acc: 7.3242e-04\n",
      "Epoch 101/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 32.2007 - acc: 0.0924 - val_loss: 32.1206 - val_acc: 0.0095\n",
      "Epoch 102/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 31.4665 - acc: 0.0951 - val_loss: 25.8180 - val_acc: 0.0322\n",
      "Epoch 103/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 32.9058 - acc: 0.0933 - val_loss: 33.3322 - val_acc: 0.0344\n",
      "Epoch 104/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 29.4395 - acc: 0.0961 - val_loss: 22.8642 - val_acc: 0.0100\n",
      "Epoch 105/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 31.4544 - acc: 0.1168 - val_loss: 32.6234 - val_acc: 0.0017\n",
      "Epoch 106/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 29.0274 - acc: 0.0969 - val_loss: 37.0719 - val_acc: 0.0029\n",
      "Epoch 107/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 40.2524 - acc: 0.1060 - val_loss: 50.8138 - val_acc: 0.0076\n",
      "Epoch 108/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 40.9679 - acc: 0.0982 - val_loss: 38.7118 - val_acc: 0.0481\n",
      "Epoch 109/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 35.5814 - acc: 0.1096 - val_loss: 36.2768 - val_acc: 0.0032\n",
      "Epoch 110/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 31.7318 - acc: 0.1266 - val_loss: 41.1657 - val_acc: 0.0034\n",
      "Epoch 111/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 35.7368 - acc: 0.0870 - val_loss: 36.2198 - val_acc: 0.0049\n",
      "Epoch 112/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 40.0684 - acc: 0.1192 - val_loss: 52.5865 - val_acc: 0.2129\n",
      "Epoch 113/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 51.9522 - acc: 0.0842 - val_loss: 48.2716 - val_acc: 0.0112\n",
      "Epoch 114/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 45.0125 - acc: 0.0996 - val_loss: 38.4344 - val_acc: 0.0103\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 4us/sample - loss: 39.2537 - acc: 0.0875 - val_loss: 34.4515 - val_acc: 0.0042\n",
      "Epoch 116/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 40.4405 - acc: 0.1210 - val_loss: 46.7998 - val_acc: 0.0020\n",
      "Epoch 117/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 38.8121 - acc: 0.1096 - val_loss: 31.3228 - val_acc: 0.0085\n",
      "Epoch 118/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 39.9200 - acc: 0.0805 - val_loss: 42.0788 - val_acc: 0.0269\n",
      "Epoch 119/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 38.2527 - acc: 0.1169 - val_loss: 40.3697 - val_acc: 0.0129\n",
      "Epoch 120/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 41.8353 - acc: 0.0837 - val_loss: 52.5395 - val_acc: 0.0137\n",
      "Epoch 121/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 45.4704 - acc: 0.1129 - val_loss: 31.0547 - val_acc: 0.0032\n",
      "Epoch 122/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 41.1545 - acc: 0.1013 - val_loss: 44.8279 - val_acc: 0.0093\n",
      "Epoch 123/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 50.9045 - acc: 0.1002 - val_loss: 54.6643 - val_acc: 0.2510\n",
      "Epoch 124/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 57.1483 - acc: 0.0978 - val_loss: 45.4831 - val_acc: 0.4917\n",
      "Epoch 125/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 57.6989 - acc: 0.1055 - val_loss: 55.0217 - val_acc: 0.0015\n",
      "Epoch 126/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 55.1604 - acc: 0.1015 - val_loss: 32.8437 - val_acc: 0.0105\n",
      "Epoch 127/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 44.9645 - acc: 0.1044 - val_loss: 50.7937 - val_acc: 0.0090\n",
      "Epoch 128/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 50.2909 - acc: 0.0847 - val_loss: 32.2744 - val_acc: 0.0691\n",
      "Epoch 129/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 46.9627 - acc: 0.1098 - val_loss: 47.6425 - val_acc: 0.0039\n",
      "Epoch 130/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 44.0063 - acc: 0.0964 - val_loss: 50.1096 - val_acc: 0.0017\n",
      "Epoch 131/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 53.5602 - acc: 0.1088 - val_loss: 61.0581 - val_acc: 0.0095\n",
      "Epoch 132/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 51.3174 - acc: 0.1017 - val_loss: 50.3980 - val_acc: 0.0244\n",
      "Epoch 133/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 46.8077 - acc: 0.1087 - val_loss: 42.8358 - val_acc: 0.0068\n",
      "Epoch 134/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 56.9310 - acc: 0.0960 - val_loss: 61.0655 - val_acc: 0.0054\n",
      "Epoch 135/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 50.8693 - acc: 0.1053 - val_loss: 53.0262 - val_acc: 0.0112\n",
      "Epoch 136/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 49.3451 - acc: 0.1136 - val_loss: 40.8936 - val_acc: 0.0012\n",
      "Epoch 137/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 45.4159 - acc: 0.0843 - val_loss: 51.0936 - val_acc: 0.0012\n",
      "Epoch 138/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 55.1062 - acc: 0.0976 - val_loss: 68.2672 - val_acc: 0.2439\n",
      "Epoch 139/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 65.8579 - acc: 0.1147 - val_loss: 45.9714 - val_acc: 0.0474\n",
      "Epoch 140/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 47.6563 - acc: 0.0784 - val_loss: 48.5833 - val_acc: 0.6990\n",
      "Epoch 141/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 54.2337 - acc: 0.1476 - val_loss: 46.9366 - val_acc: 0.0012\n",
      "Epoch 142/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 59.5719 - acc: 0.0704 - val_loss: 84.4649 - val_acc: 0.0212\n",
      "Epoch 143/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 66.2403 - acc: 0.1182 - val_loss: 83.6663 - val_acc: 0.0347\n",
      "Epoch 144/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 74.6131 - acc: 0.0885 - val_loss: 69.9930 - val_acc: 0.0059\n",
      "Epoch 145/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 61.2124 - acc: 0.0741 - val_loss: 62.0847 - val_acc: 0.0710\n",
      "Epoch 146/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 68.4527 - acc: 0.1169 - val_loss: 68.6413 - val_acc: 0.0012\n",
      "Epoch 147/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 60.9365 - acc: 0.0873 - val_loss: 73.9704 - val_acc: 9.7656e-04\n",
      "Epoch 148/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 61.8845 - acc: 0.0978 - val_loss: 51.4086 - val_acc: 0.0525\n",
      "Epoch 149/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 69.5484 - acc: 0.1127 - val_loss: 72.5821 - val_acc: 0.0117\n",
      "Epoch 150/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 71.0268 - acc: 0.1075 - val_loss: 62.5685 - val_acc: 4.8828e-04\n",
      "Epoch 151/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 56.7950 - acc: 0.0800 - val_loss: 59.0634 - val_acc: 7.3242e-04\n",
      "Epoch 152/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 70.6418 - acc: 0.0957 - val_loss: 75.0888 - val_acc: 0.0315\n",
      "Epoch 153/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 70.2344 - acc: 0.0943 - val_loss: 81.5666 - val_acc: 0.0054\n",
      "Epoch 154/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 74.6068 - acc: 0.0985 - val_loss: 81.2278 - val_acc: 0.2424\n",
      "Epoch 155/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 71.3661 - acc: 0.1074 - val_loss: 68.3820 - val_acc: 0.0171\n",
      "Epoch 156/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 76.9045 - acc: 0.0866 - val_loss: 77.2006 - val_acc: 0.0110\n",
      "Epoch 157/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 70.4050 - acc: 0.0926 - val_loss: 92.9992 - val_acc: 0.0112\n",
      "Epoch 158/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 78.0877 - acc: 0.1055 - val_loss: 41.2314 - val_acc: 0.0139\n",
      "Epoch 159/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 59.0811 - acc: 0.0846 - val_loss: 65.3402 - val_acc: 0.0059\n",
      "Epoch 160/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 68.8937 - acc: 0.1053 - val_loss: 63.9753 - val_acc: 0.2502\n",
      "Epoch 161/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 76.3540 - acc: 0.1067 - val_loss: 64.8443 - val_acc: 0.0032\n",
      "Epoch 162/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 72.4216 - acc: 0.1104 - val_loss: 77.3639 - val_acc: 0.0156\n",
      "Epoch 163/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 85.3395 - acc: 0.0953 - val_loss: 93.2791 - val_acc: 0.0229\n",
      "Epoch 164/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 84.2589 - acc: 0.0880 - val_loss: 78.3312 - val_acc: 0.0188\n",
      "Epoch 165/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 64.0188 - acc: 0.0846 - val_loss: 50.0637 - val_acc: 0.0112\n",
      "Epoch 166/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 66.3160 - acc: 0.1404 - val_loss: 69.2765 - val_acc: 0.2480\n",
      "Epoch 167/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 81.1522 - acc: 0.0750 - val_loss: 59.8711 - val_acc: 0.0200\n",
      "Epoch 168/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 82.9058 - acc: 0.1025 - val_loss: 101.4777 - val_acc: 2.4414e-04\n",
      "Epoch 169/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 81.1841 - acc: 0.0843 - val_loss: 88.0282 - val_acc: 0.2471\n",
      "Epoch 170/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 70.8917 - acc: 0.1260 - val_loss: 59.0952 - val_acc: 0.0220\n",
      "Epoch 171/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 74.5837 - acc: 0.0827 - val_loss: 78.6611 - val_acc: 9.7656e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 78.8789 - acc: 0.1184 - val_loss: 55.2596 - val_acc: 0.0115\n",
      "Epoch 173/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 78.9510 - acc: 0.0842 - val_loss: 90.3986 - val_acc: 0.0012\n",
      "Epoch 174/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 79.4770 - acc: 0.1011 - val_loss: 76.3645 - val_acc: 0.6699\n",
      "Epoch 175/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 77.2860 - acc: 0.1019 - val_loss: 97.9684 - val_acc: 0.0012\n",
      "Epoch 176/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 81.0541 - acc: 0.0905 - val_loss: 58.2234 - val_acc: 0.0032\n",
      "Epoch 177/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 88.6295 - acc: 0.1205 - val_loss: 123.6025 - val_acc: 9.7656e-04\n",
      "Epoch 178/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 90.0408 - acc: 0.0847 - val_loss: 75.3024 - val_acc: 0.0339\n",
      "Epoch 179/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 73.9835 - acc: 0.1004 - val_loss: 90.7071 - val_acc: 0.0015\n",
      "Epoch 180/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 85.4913 - acc: 0.1047 - val_loss: 88.9492 - val_acc: 0.0020\n",
      "Epoch 181/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 90.1819 - acc: 0.0895 - val_loss: 103.1727 - val_acc: 0.0439\n",
      "Epoch 182/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 100.7121 - acc: 0.1153 - val_loss: 71.4802 - val_acc: 0.0098\n",
      "Epoch 183/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 81.2340 - acc: 0.1284 - val_loss: 87.1831 - val_acc: 0.0103\n",
      "Epoch 184/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 103.0996 - acc: 0.0735 - val_loss: 74.1759 - val_acc: 0.0012\n",
      "Epoch 185/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 89.6446 - acc: 0.0961 - val_loss: 97.6153 - val_acc: 0.6453\n",
      "Epoch 186/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 91.0402 - acc: 0.1100 - val_loss: 94.2418 - val_acc: 0.2344\n",
      "Epoch 187/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 88.1731 - acc: 0.1065 - val_loss: 134.2021 - val_acc: 0.0020\n",
      "Epoch 188/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 105.3671 - acc: 0.0821 - val_loss: 91.7167 - val_acc: 0.0525\n",
      "Epoch 189/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 82.1043 - acc: 0.1017 - val_loss: 82.2318 - val_acc: 0.0835\n",
      "Epoch 190/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 72.4785 - acc: 0.0899 - val_loss: 106.6984 - val_acc: 0.0046\n",
      "Epoch 191/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 93.7963 - acc: 0.1217 - val_loss: 123.1043 - val_acc: 0.0020\n",
      "Epoch 192/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 95.3185 - acc: 0.0878 - val_loss: 77.4598 - val_acc: 0.0020\n",
      "Epoch 193/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 78.3593 - acc: 0.1293 - val_loss: 112.8434 - val_acc: 7.3242e-04\n",
      "Epoch 194/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 94.2704 - acc: 0.0759 - val_loss: 69.5195 - val_acc: 0.2461\n",
      "Epoch 195/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 84.5879 - acc: 0.1183 - val_loss: 117.5027 - val_acc: 0.0024\n",
      "Epoch 196/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 100.1919 - acc: 0.0767 - val_loss: 98.5927 - val_acc: 0.7087\n",
      "Epoch 197/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 99.6653 - acc: 0.1385 - val_loss: 123.1698 - val_acc: 0.0029\n",
      "Epoch 198/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 100.7276 - acc: 0.0877 - val_loss: 106.8127 - val_acc: 0.0208\n",
      "Epoch 199/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 89.2778 - acc: 0.0948 - val_loss: 85.1360 - val_acc: 0.0166\n",
      "Epoch 200/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 79.2451 - acc: 0.0791 - val_loss: 78.9861 - val_acc: 0.0535\n",
      "Epoch 201/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 82.5629 - acc: 0.0906 - val_loss: 88.4554 - val_acc: 0.0308\n",
      "Epoch 202/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 101.1805 - acc: 0.1258 - val_loss: 80.0696 - val_acc: 0.2141\n",
      "Epoch 203/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 92.3815 - acc: 0.1001 - val_loss: 133.6488 - val_acc: 4.8828e-04\n",
      "Epoch 204/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 91.8040 - acc: 0.1049 - val_loss: 95.1673 - val_acc: 0.0042\n",
      "Epoch 205/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 118.3737 - acc: 0.0954 - val_loss: 87.0705 - val_acc: 0.0022\n",
      "Epoch 206/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 89.5522 - acc: 0.0961 - val_loss: 99.2733 - val_acc: 0.0059\n",
      "Epoch 207/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 104.0008 - acc: 0.1126 - val_loss: 130.8677 - val_acc: 0.0198\n",
      "Epoch 208/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 134.5029 - acc: 0.0761 - val_loss: 124.0531 - val_acc: 0.2490\n",
      "Epoch 209/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 93.1096 - acc: 0.0914 - val_loss: 110.3039 - val_acc: 0.0242\n",
      "Epoch 210/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 114.7120 - acc: 0.1080 - val_loss: 83.4342 - val_acc: 0.2485\n",
      "Epoch 211/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 100.7549 - acc: 0.0828 - val_loss: 118.0842 - val_acc: 0.0032\n",
      "Epoch 212/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 119.6187 - acc: 0.1396 - val_loss: 137.6171 - val_acc: 0.0229\n",
      "Epoch 213/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 123.4400 - acc: 0.0833 - val_loss: 122.9395 - val_acc: 0.0583\n",
      "Epoch 214/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 115.2801 - acc: 0.0858 - val_loss: 136.1416 - val_acc: 0.0059\n",
      "Epoch 215/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 100.2394 - acc: 0.0873 - val_loss: 167.4748 - val_acc: 0.0320\n",
      "Epoch 216/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 123.4421 - acc: 0.1462 - val_loss: 84.9417 - val_acc: 7.3242e-04\n",
      "Epoch 217/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 114.0990 - acc: 0.0829 - val_loss: 114.5620 - val_acc: 0.0032\n",
      "Epoch 218/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 102.4403 - acc: 0.0842 - val_loss: 61.0157 - val_acc: 0.0161\n",
      "Epoch 219/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 116.7472 - acc: 0.1096 - val_loss: 105.7618 - val_acc: 0.0020\n",
      "Epoch 220/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 95.5735 - acc: 0.1065 - val_loss: 90.1227 - val_acc: 0.0129\n",
      "Epoch 221/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 114.6598 - acc: 0.0919 - val_loss: 116.0054 - val_acc: 0.0012\n",
      "Epoch 222/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 113.0502 - acc: 0.0830 - val_loss: 101.6521 - val_acc: 0.0288\n",
      "Epoch 223/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 118.8502 - acc: 0.1356 - val_loss: 120.8119 - val_acc: 0.0103\n",
      "Epoch 224/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 137.9581 - acc: 0.0820 - val_loss: 136.7012 - val_acc: 7.3242e-04\n",
      "Epoch 225/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 140.1246 - acc: 0.0790 - val_loss: 117.7860 - val_acc: 0.0535\n",
      "Epoch 226/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 117.6201 - acc: 0.1274 - val_loss: 131.8142 - val_acc: 0.0073\n",
      "Epoch 227/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 127.8329 - acc: 0.1060 - val_loss: 97.5626 - val_acc: 0.0015\n",
      "Epoch 228/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 4us/sample - loss: 102.3779 - acc: 0.0819 - val_loss: 92.5648 - val_acc: 0.0039\n",
      "Epoch 229/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 97.3291 - acc: 0.1126 - val_loss: 141.2544 - val_acc: 0.0020\n",
      "Epoch 230/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 151.1746 - acc: 0.0914 - val_loss: 134.4244 - val_acc: 0.6265\n",
      "Epoch 231/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 142.5137 - acc: 0.0951 - val_loss: 119.9771 - val_acc: 7.3242e-04\n",
      "Epoch 232/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 123.8448 - acc: 0.1335 - val_loss: 173.3739 - val_acc: 0.2458\n",
      "Epoch 233/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 165.8466 - acc: 0.0917 - val_loss: 180.7048 - val_acc: 4.8828e-04\n",
      "Epoch 234/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 155.8577 - acc: 0.0758 - val_loss: 165.4807 - val_acc: 4.8828e-04\n",
      "Epoch 235/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 172.0875 - acc: 0.0966 - val_loss: 171.4204 - val_acc: 0.0142\n",
      "Epoch 236/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 143.0876 - acc: 0.1141 - val_loss: 134.8252 - val_acc: 9.7656e-04\n",
      "Epoch 237/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 127.7979 - acc: 0.0775 - val_loss: 124.0945 - val_acc: 7.3242e-04\n",
      "Epoch 238/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 144.8377 - acc: 0.1140 - val_loss: 152.7156 - val_acc: 9.7656e-04\n",
      "Epoch 239/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 169.2047 - acc: 0.1124 - val_loss: 200.5506 - val_acc: 0.0105\n",
      "Epoch 240/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 157.1700 - acc: 0.0894 - val_loss: 206.7451 - val_acc: 0.0105\n",
      "Epoch 241/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 163.2100 - acc: 0.0869 - val_loss: 145.0459 - val_acc: 0.2505\n",
      "Epoch 242/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 134.2326 - acc: 0.1150 - val_loss: 156.0037 - val_acc: 0.0012\n",
      "Epoch 243/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 140.0324 - acc: 0.1279 - val_loss: 123.6108 - val_acc: 0.0017\n",
      "Epoch 244/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 132.5935 - acc: 0.0814 - val_loss: 139.6782 - val_acc: 4.8828e-04\n",
      "Epoch 245/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 118.3162 - acc: 0.1072 - val_loss: 136.4208 - val_acc: 0.0012\n",
      "Epoch 246/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 154.1818 - acc: 0.0908 - val_loss: 141.0115 - val_acc: 0.0015\n",
      "Epoch 247/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 116.4500 - acc: 0.1143 - val_loss: 161.1122 - val_acc: 7.3242e-04\n",
      "Epoch 248/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 167.4344 - acc: 0.0809 - val_loss: 172.0593 - val_acc: 0.0039\n",
      "Epoch 249/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 157.6391 - acc: 0.1074 - val_loss: 208.7104 - val_acc: 0.2485\n",
      "Epoch 250/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 175.8758 - acc: 0.1083 - val_loss: 161.0486 - val_acc: 0.2485\n",
      "Epoch 251/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 171.0260 - acc: 0.1070 - val_loss: 160.8800 - val_acc: 0.0022\n",
      "Epoch 252/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 147.7202 - acc: 0.0747 - val_loss: 131.8458 - val_acc: 0.6372\n",
      "Epoch 253/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 161.1440 - acc: 0.1120 - val_loss: 134.6954 - val_acc: 0.0674\n",
      "Epoch 254/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 150.1119 - acc: 0.0839 - val_loss: 113.4636 - val_acc: 0.0129\n",
      "Epoch 255/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 99.2275 - acc: 0.0890 - val_loss: 123.7639 - val_acc: 0.0042\n",
      "Epoch 256/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 131.7982 - acc: 0.1157 - val_loss: 198.7108 - val_acc: 0.0017\n",
      "Epoch 257/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 187.1270 - acc: 0.0829 - val_loss: 169.1033 - val_acc: 7.3242e-04\n",
      "Epoch 258/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 151.5303 - acc: 0.0983 - val_loss: 171.5953 - val_acc: 0.0029\n",
      "Epoch 259/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 159.0453 - acc: 0.0915 - val_loss: 150.7619 - val_acc: 0.0027\n",
      "Epoch 260/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 168.1404 - acc: 0.1060 - val_loss: 187.6145 - val_acc: 0.0029\n",
      "Epoch 261/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 163.9322 - acc: 0.0849 - val_loss: 176.4736 - val_acc: 0.6714\n",
      "Epoch 262/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 148.8159 - acc: 0.1113 - val_loss: 164.0734 - val_acc: 0.0122\n",
      "Epoch 263/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 165.9417 - acc: 0.0934 - val_loss: 152.9542 - val_acc: 0.0168\n",
      "Epoch 264/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 183.8080 - acc: 0.1061 - val_loss: 201.9888 - val_acc: 2.4414e-04\n",
      "Epoch 265/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 151.9020 - acc: 0.0791 - val_loss: 156.5129 - val_acc: 0.0122\n",
      "Epoch 266/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 183.1148 - acc: 0.1282 - val_loss: 167.4471 - val_acc: 0.0032\n",
      "Epoch 267/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 177.2325 - acc: 0.0954 - val_loss: 183.8987 - val_acc: 0.2490\n",
      "Epoch 268/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 200.5435 - acc: 0.0787 - val_loss: 173.0281 - val_acc: 0.2507\n",
      "Epoch 269/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 166.9232 - acc: 0.1047 - val_loss: 186.0221 - val_acc: 0.0015\n",
      "Epoch 270/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 185.7568 - acc: 0.1192 - val_loss: 167.0755 - val_acc: 4.8828e-04\n",
      "Epoch 271/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 174.7500 - acc: 0.0757 - val_loss: 138.1314 - val_acc: 0.0029\n",
      "Epoch 272/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 180.2680 - acc: 0.0925 - val_loss: 185.5313 - val_acc: 0.2434\n",
      "Epoch 273/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 198.0502 - acc: 0.1118 - val_loss: 183.5705 - val_acc: 0.0303\n",
      "Epoch 274/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 208.4871 - acc: 0.1072 - val_loss: 156.8077 - val_acc: 4.8828e-04\n",
      "Epoch 275/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 155.0562 - acc: 0.0778 - val_loss: 180.2353 - val_acc: 0.0046\n",
      "Epoch 276/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 184.9058 - acc: 0.1144 - val_loss: 146.2317 - val_acc: 4.8828e-04\n",
      "Epoch 277/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 145.8222 - acc: 0.0866 - val_loss: 166.1848 - val_acc: 0.0327\n",
      "Epoch 278/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 161.4353 - acc: 0.0955 - val_loss: 149.5131 - val_acc: 0.0020\n",
      "Epoch 279/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 152.0374 - acc: 0.1140 - val_loss: 92.0566 - val_acc: 0.0039\n",
      "Epoch 280/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 173.4625 - acc: 0.0925 - val_loss: 191.9579 - val_acc: 0.2483\n",
      "Epoch 281/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 170.2339 - acc: 0.1201 - val_loss: 151.2495 - val_acc: 0.0020\n",
      "Epoch 282/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 148.4338 - acc: 0.0789 - val_loss: 180.0911 - val_acc: 0.7114\n",
      "Epoch 283/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 148.6216 - acc: 0.0949 - val_loss: 127.9583 - val_acc: 0.5916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 155.7669 - acc: 0.1346 - val_loss: 212.7461 - val_acc: 0.0012\n",
      "Epoch 285/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 218.3911 - acc: 0.0796 - val_loss: 198.9000 - val_acc: 0.0037\n",
      "Epoch 286/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 191.4332 - acc: 0.1280 - val_loss: 128.7810 - val_acc: 0.0015\n",
      "Epoch 287/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 183.7412 - acc: 0.0978 - val_loss: 190.8304 - val_acc: 0.0012\n",
      "Epoch 288/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 197.8921 - acc: 0.0785 - val_loss: 262.3516 - val_acc: 0.7173\n",
      "Epoch 289/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 252.9313 - acc: 0.1116 - val_loss: 256.5532 - val_acc: 0.0012\n",
      "Epoch 290/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 179.1425 - acc: 0.1030 - val_loss: 246.0060 - val_acc: 0.7205\n",
      "Epoch 291/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 198.1408 - acc: 0.1214 - val_loss: 230.2772 - val_acc: 2.4414e-04\n",
      "Epoch 292/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 186.0866 - acc: 0.0846 - val_loss: 226.0163 - val_acc: 7.3242e-04\n",
      "Epoch 293/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 172.8607 - acc: 0.1336 - val_loss: 106.7904 - val_acc: 2.4414e-04\n",
      "Epoch 294/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 178.8346 - acc: 0.0811 - val_loss: 249.2760 - val_acc: 2.4414e-04\n",
      "Epoch 295/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 214.4033 - acc: 0.0794 - val_loss: 246.7341 - val_acc: 0.0303\n",
      "Epoch 296/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 222.0599 - acc: 0.0927 - val_loss: 175.7658 - val_acc: 0.2336\n",
      "Epoch 297/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 207.0665 - acc: 0.1161 - val_loss: 170.8600 - val_acc: 0.0042\n",
      "Epoch 298/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 166.7963 - acc: 0.0852 - val_loss: 135.1194 - val_acc: 0.6089\n",
      "Epoch 299/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 163.7174 - acc: 0.1502 - val_loss: 159.6811 - val_acc: 7.3242e-04\n",
      "Epoch 300/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 182.2665 - acc: 0.0842 - val_loss: 179.4951 - val_acc: 0.0034\n",
      "Epoch 301/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 202.2787 - acc: 0.0940 - val_loss: 241.3886 - val_acc: 2.4414e-04\n",
      "Epoch 302/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 255.9437 - acc: 0.1242 - val_loss: 273.8093 - val_acc: 0.0073\n",
      "Epoch 303/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 256.5096 - acc: 0.0800 - val_loss: 190.2282 - val_acc: 4.8828e-04\n",
      "Epoch 304/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 205.2399 - acc: 0.0965 - val_loss: 233.9249 - val_acc: 4.8828e-04\n",
      "Epoch 305/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 190.6685 - acc: 0.0959 - val_loss: 245.2402 - val_acc: 0.0012\n",
      "Epoch 306/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 179.2679 - acc: 0.0860 - val_loss: 153.2503 - val_acc: 0.0012\n",
      "Epoch 307/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 198.7201 - acc: 0.0711 - val_loss: 212.7123 - val_acc: 0.0054\n",
      "Epoch 308/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 180.7930 - acc: 0.1375 - val_loss: 176.4830 - val_acc: 4.8828e-04\n",
      "Epoch 309/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 212.5721 - acc: 0.0746 - val_loss: 230.5429 - val_acc: 0.2478\n",
      "Epoch 310/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 197.4293 - acc: 0.0807 - val_loss: 118.3663 - val_acc: 0.8408\n",
      "Epoch 311/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 195.0307 - acc: 0.1055 - val_loss: 205.1453 - val_acc: 0.0032\n",
      "Epoch 312/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 209.3510 - acc: 0.1126 - val_loss: 159.9252 - val_acc: 2.4414e-04\n",
      "Epoch 313/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 198.8469 - acc: 0.0816 - val_loss: 278.6526 - val_acc: 0.0103\n",
      "Epoch 314/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 203.9219 - acc: 0.1223 - val_loss: 139.2068 - val_acc: 0.0012\n",
      "Epoch 315/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 137.1976 - acc: 0.0941 - val_loss: 154.5599 - val_acc: 0.0103\n",
      "Epoch 316/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 172.3482 - acc: 0.1199 - val_loss: 170.5122 - val_acc: 4.8828e-04\n",
      "Epoch 317/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 157.0563 - acc: 0.0791 - val_loss: 100.8936 - val_acc: 0.0391\n",
      "Epoch 318/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 196.5390 - acc: 0.0896 - val_loss: 284.5066 - val_acc: 0.0654\n",
      "Epoch 319/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 226.6643 - acc: 0.1358 - val_loss: 200.7080 - val_acc: 0.0039\n",
      "Epoch 320/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 209.2690 - acc: 0.0850 - val_loss: 227.0365 - val_acc: 0.0090\n",
      "Epoch 321/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 231.3802 - acc: 0.0979 - val_loss: 186.9275 - val_acc: 9.7656e-04\n",
      "Epoch 322/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 170.9415 - acc: 0.1214 - val_loss: 219.2072 - val_acc: 2.4414e-04\n",
      "Epoch 323/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 282.7363 - acc: 0.0941 - val_loss: 253.5602 - val_acc: 2.4414e-04\n",
      "Epoch 324/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 262.2916 - acc: 0.0722 - val_loss: 187.1809 - val_acc: 0.0015\n",
      "Epoch 325/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 253.9765 - acc: 0.0782 - val_loss: 223.2512 - val_acc: 0.0398\n",
      "Epoch 326/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 258.1285 - acc: 0.1076 - val_loss: 206.9994 - val_acc: 0.0483\n",
      "Epoch 327/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 236.7775 - acc: 0.1210 - val_loss: 229.7552 - val_acc: 0.0042\n",
      "Epoch 328/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 232.4314 - acc: 0.0766 - val_loss: 192.2444 - val_acc: 0.0505\n",
      "Epoch 329/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 264.7955 - acc: 0.1184 - val_loss: 268.3023 - val_acc: 0.0225\n",
      "Epoch 330/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 226.5889 - acc: 0.0947 - val_loss: 160.5552 - val_acc: 0.0085\n",
      "Epoch 331/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 196.0619 - acc: 0.1088 - val_loss: 176.2122 - val_acc: 0.0210\n",
      "Epoch 332/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 239.4462 - acc: 0.1179 - val_loss: 263.6974 - val_acc: 0.0032\n",
      "Epoch 333/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 219.8478 - acc: 0.0944 - val_loss: 261.7164 - val_acc: 4.8828e-04\n",
      "Epoch 334/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 236.3726 - acc: 0.0825 - val_loss: 197.4633 - val_acc: 0.0046\n",
      "Epoch 335/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 212.0574 - acc: 0.1199 - val_loss: 326.2935 - val_acc: 0.0044\n",
      "Epoch 336/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 229.7787 - acc: 0.1080 - val_loss: 222.8741 - val_acc: 2.4414e-04\n",
      "Epoch 337/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 186.2303 - acc: 0.0846 - val_loss: 179.9331 - val_acc: 0.6946\n",
      "Epoch 338/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 237.2333 - acc: 0.0762 - val_loss: 314.0137 - val_acc: 0.0012\n",
      "Epoch 339/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 4us/sample - loss: 236.3419 - acc: 0.1069 - val_loss: 286.1452 - val_acc: 0.0017\n",
      "Epoch 340/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 290.9677 - acc: 0.1074 - val_loss: 276.1311 - val_acc: 7.3242e-04\n",
      "Epoch 341/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 241.5102 - acc: 0.1054 - val_loss: 184.3664 - val_acc: 0.0012\n",
      "Epoch 342/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 202.3507 - acc: 0.0752 - val_loss: 228.9630 - val_acc: 0.0122\n",
      "Epoch 343/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 295.4917 - acc: 0.1050 - val_loss: 282.4711 - val_acc: 0.0122\n",
      "Epoch 344/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 226.0888 - acc: 0.1125 - val_loss: 167.6267 - val_acc: 0.0454\n",
      "Epoch 345/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 240.3422 - acc: 0.0926 - val_loss: 251.4843 - val_acc: 4.8828e-04\n",
      "Epoch 346/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 294.2403 - acc: 0.0685 - val_loss: 389.8948 - val_acc: 0.0139\n",
      "Epoch 347/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 285.0503 - acc: 0.1494 - val_loss: 236.5438 - val_acc: 2.4414e-04\n",
      "Epoch 348/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 242.6776 - acc: 0.0812 - val_loss: 218.5502 - val_acc: 4.8828e-04\n",
      "Epoch 349/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 207.5236 - acc: 0.0967 - val_loss: 194.4497 - val_acc: 7.3242e-04\n",
      "Epoch 350/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 196.0001 - acc: 0.0904 - val_loss: 356.4306 - val_acc: 7.3242e-04\n",
      "Epoch 351/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 295.6798 - acc: 0.0865 - val_loss: 283.4849 - val_acc: 0.0154\n",
      "Epoch 352/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 257.1012 - acc: 0.1126 - val_loss: 233.1396 - val_acc: 0.0171\n",
      "Epoch 353/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 237.2566 - acc: 0.1153 - val_loss: 159.5373 - val_acc: 0.0107\n",
      "Epoch 354/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 264.7289 - acc: 0.0844 - val_loss: 218.3510 - val_acc: 0.2490\n",
      "Epoch 355/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 260.5732 - acc: 0.1007 - val_loss: 267.7089 - val_acc: 0.0037\n",
      "Epoch 356/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 253.8302 - acc: 0.1102 - val_loss: 298.0824 - val_acc: 0.0032\n",
      "Epoch 357/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 255.7190 - acc: 0.1044 - val_loss: 290.5050 - val_acc: 0.0046\n",
      "Epoch 358/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 247.5645 - acc: 0.0851 - val_loss: 218.1160 - val_acc: 0.7678\n",
      "Epoch 359/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 233.8281 - acc: 0.1518 - val_loss: 212.8423 - val_acc: 0.0027\n",
      "Epoch 360/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 276.8383 - acc: 0.0954 - val_loss: 350.7848 - val_acc: 2.4414e-04\n",
      "Epoch 361/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 294.8426 - acc: 0.1100 - val_loss: 246.4661 - val_acc: 2.4414e-04\n",
      "Epoch 362/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 345.1652 - acc: 0.0840 - val_loss: 306.3193 - val_acc: 0.0012\n",
      "Epoch 363/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 277.4457 - acc: 0.0779 - val_loss: 212.9958 - val_acc: 0.2493\n",
      "Epoch 364/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 275.2301 - acc: 0.0940 - val_loss: 347.2790 - val_acc: 0.0032\n",
      "Epoch 365/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 315.4391 - acc: 0.1106 - val_loss: 246.4332 - val_acc: 0.0093\n",
      "Epoch 366/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 265.6743 - acc: 0.1216 - val_loss: 195.5550 - val_acc: 0.0032\n",
      "Epoch 367/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 250.6081 - acc: 0.0852 - val_loss: 225.5054 - val_acc: 0.0024\n",
      "Epoch 368/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 276.3150 - acc: 0.0984 - val_loss: 283.1486 - val_acc: 4.8828e-04\n",
      "Epoch 369/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 220.9444 - acc: 0.1226 - val_loss: 193.0454 - val_acc: 0.0012\n",
      "Epoch 370/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 257.8902 - acc: 0.0942 - val_loss: 262.2198 - val_acc: 4.8828e-04\n",
      "Epoch 371/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 276.1287 - acc: 0.0799 - val_loss: 305.5254 - val_acc: 0.0110\n",
      "Epoch 372/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 329.0628 - acc: 0.1081 - val_loss: 315.9618 - val_acc: 0.0073\n",
      "Epoch 373/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 383.8513 - acc: 0.1313 - val_loss: 384.2231 - val_acc: 9.7656e-04\n",
      "Epoch 374/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 273.7331 - acc: 0.0611 - val_loss: 237.3899 - val_acc: 0.0017\n",
      "Epoch 375/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 327.6787 - acc: 0.0994 - val_loss: 414.1395 - val_acc: 0.0017\n",
      "Epoch 376/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 329.6676 - acc: 0.0926 - val_loss: 336.6719 - val_acc: 0.0066\n",
      "Epoch 377/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 286.2206 - acc: 0.1170 - val_loss: 228.5662 - val_acc: 0.0195\n",
      "Epoch 378/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 248.6559 - acc: 0.0988 - val_loss: 238.0640 - val_acc: 0.2490\n",
      "Epoch 379/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 218.3646 - acc: 0.0963 - val_loss: 367.2557 - val_acc: 4.8828e-04\n",
      "Epoch 380/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 329.8050 - acc: 0.0789 - val_loss: 373.7611 - val_acc: 0.0056\n",
      "Epoch 381/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 289.3035 - acc: 0.1144 - val_loss: 232.5270 - val_acc: 0.0044\n",
      "Epoch 382/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 334.8407 - acc: 0.0845 - val_loss: 295.1094 - val_acc: 0.0073\n",
      "Epoch 383/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 280.0370 - acc: 0.1253 - val_loss: 355.2359 - val_acc: 2.4414e-04\n",
      "Epoch 384/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 353.4297 - acc: 0.0951 - val_loss: 286.2054 - val_acc: 0.0015\n",
      "Epoch 385/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 351.1149 - acc: 0.1172 - val_loss: 291.4387 - val_acc: 0.2490\n",
      "Epoch 386/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 295.9989 - acc: 0.0942 - val_loss: 274.4349 - val_acc: 0.0039\n",
      "Epoch 387/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 308.4930 - acc: 0.1026 - val_loss: 293.6730 - val_acc: 9.7656e-04\n",
      "Epoch 388/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 283.3012 - acc: 0.1138 - val_loss: 231.6853 - val_acc: 7.3242e-04\n",
      "Epoch 389/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 260.5182 - acc: 0.1093 - val_loss: 211.6342 - val_acc: 9.7656e-04\n",
      "Epoch 390/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 303.5006 - acc: 0.0836 - val_loss: 325.5496 - val_acc: 2.4414e-04\n",
      "Epoch 391/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 332.9000 - acc: 0.0903 - val_loss: 378.1291 - val_acc: 9.7656e-04\n",
      "Epoch 392/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 373.8641 - acc: 0.0991 - val_loss: 416.2987 - val_acc: 7.3242e-04\n",
      "Epoch 393/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 333.8426 - acc: 0.0952 - val_loss: 354.2141 - val_acc: 9.7656e-04\n",
      "Epoch 394/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 5us/sample - loss: 323.6445 - acc: 0.0940 - val_loss: 362.3983 - val_acc: 0.9829\n",
      "Epoch 395/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 263.9003 - acc: 0.1151 - val_loss: 173.9963 - val_acc: 0.0281\n",
      "Epoch 396/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 279.7705 - acc: 0.0821 - val_loss: 221.4738 - val_acc: 4.8828e-04\n",
      "Epoch 397/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 335.2812 - acc: 0.1021 - val_loss: 318.6540 - val_acc: 2.4414e-04\n",
      "Epoch 398/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 351.8888 - acc: 0.0877 - val_loss: 406.1841 - val_acc: 7.3242e-04\n",
      "Epoch 399/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 321.9626 - acc: 0.0960 - val_loss: 274.2496 - val_acc: 0.0051\n",
      "Epoch 400/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 262.5744 - acc: 0.0919 - val_loss: 313.7193 - val_acc: 0.0029\n",
      "Epoch 401/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 280.1145 - acc: 0.0830 - val_loss: 282.0303 - val_acc: 2.4414e-04\n",
      "Epoch 402/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 286.2822 - acc: 0.1251 - val_loss: 384.9955 - val_acc: 0.0029\n",
      "Epoch 403/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 325.7288 - acc: 0.0646 - val_loss: 205.9408 - val_acc: 0.2507\n",
      "Epoch 404/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 296.9615 - acc: 0.1055 - val_loss: 362.0723 - val_acc: 0.0037\n",
      "Epoch 405/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 339.8724 - acc: 0.1023 - val_loss: 364.9427 - val_acc: 4.8828e-04\n",
      "Epoch 406/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 350.6023 - acc: 0.0913 - val_loss: 240.8885 - val_acc: 4.8828e-04\n",
      "Epoch 407/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 282.2380 - acc: 0.0856 - val_loss: 286.2315 - val_acc: 0.7058\n",
      "Epoch 408/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 344.8235 - acc: 0.1205 - val_loss: 290.2356 - val_acc: 2.4414e-04\n",
      "Epoch 409/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 316.2080 - acc: 0.0788 - val_loss: 366.7343 - val_acc: 0.2493\n",
      "Epoch 410/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 340.9941 - acc: 0.0806 - val_loss: 457.0304 - val_acc: 9.7656e-04\n",
      "Epoch 411/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 370.0126 - acc: 0.1153 - val_loss: 394.1760 - val_acc: 0.0159\n",
      "Epoch 412/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 396.3946 - acc: 0.0901 - val_loss: 409.7074 - val_acc: 0.0098\n",
      "Epoch 413/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 415.8526 - acc: 0.1086 - val_loss: 305.0230 - val_acc: 0.0076\n",
      "Epoch 414/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 290.1434 - acc: 0.0923 - val_loss: 313.7309 - val_acc: 0.0017\n",
      "Epoch 415/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 343.5504 - acc: 0.1113 - val_loss: 261.7384 - val_acc: 0.6946\n",
      "Epoch 416/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 349.5877 - acc: 0.0966 - val_loss: 325.1284 - val_acc: 0.0012\n",
      "Epoch 417/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 311.2305 - acc: 0.0833 - val_loss: 332.7801 - val_acc: 0.2705\n",
      "Epoch 418/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 385.0486 - acc: 0.1341 - val_loss: 330.5810 - val_acc: 9.7656e-04\n",
      "Epoch 419/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 375.3000 - acc: 0.1168 - val_loss: 398.2628 - val_acc: 4.8828e-04\n",
      "Epoch 420/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 358.6949 - acc: 0.0761 - val_loss: 382.4447 - val_acc: 7.3242e-04\n",
      "Epoch 421/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 346.9751 - acc: 0.0912 - val_loss: 390.6836 - val_acc: 0.0076\n",
      "Epoch 422/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 414.8505 - acc: 0.1004 - val_loss: 513.0109 - val_acc: 4.8828e-04\n",
      "Epoch 423/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 380.9292 - acc: 0.1161 - val_loss: 311.9801 - val_acc: 0.0012\n",
      "Epoch 424/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 360.5782 - acc: 0.1075 - val_loss: 269.1460 - val_acc: 0.2488\n",
      "Epoch 425/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 372.0599 - acc: 0.1205 - val_loss: 457.3630 - val_acc: 4.8828e-04\n",
      "Epoch 426/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 412.8301 - acc: 0.0887 - val_loss: 454.3685 - val_acc: 0.0020\n",
      "Epoch 427/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 382.1355 - acc: 0.0805 - val_loss: 386.2533 - val_acc: 0.0000e+00\n",
      "Epoch 428/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 376.6828 - acc: 0.0933 - val_loss: 361.3540 - val_acc: 0.2952\n",
      "Epoch 429/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 395.8673 - acc: 0.1229 - val_loss: 378.1119 - val_acc: 0.0000e+00\n",
      "Epoch 430/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 313.6469 - acc: 0.0813 - val_loss: 290.4752 - val_acc: 0.0000e+00\n",
      "Epoch 431/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 342.2534 - acc: 0.1012 - val_loss: 371.7149 - val_acc: 2.4414e-04\n",
      "Epoch 432/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 393.2083 - acc: 0.0983 - val_loss: 344.0415 - val_acc: 0.6196\n",
      "Epoch 433/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 392.4960 - acc: 0.0882 - val_loss: 407.1879 - val_acc: 0.0029\n",
      "Epoch 434/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 379.3867 - acc: 0.0980 - val_loss: 373.7511 - val_acc: 0.0046\n",
      "Epoch 435/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 365.6711 - acc: 0.0990 - val_loss: 433.7164 - val_acc: 0.2495\n",
      "Epoch 436/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 363.2971 - acc: 0.0802 - val_loss: 437.8969 - val_acc: 0.0669\n",
      "Epoch 437/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 429.9479 - acc: 0.1137 - val_loss: 456.9458 - val_acc: 0.2495\n",
      "Epoch 438/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 381.4064 - acc: 0.0991 - val_loss: 329.1954 - val_acc: 0.6467\n",
      "Epoch 439/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 381.2732 - acc: 0.1130 - val_loss: 341.9104 - val_acc: 0.0000e+00\n",
      "Epoch 440/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 390.2344 - acc: 0.0864 - val_loss: 484.9357 - val_acc: 2.4414e-04\n",
      "Epoch 441/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 384.6041 - acc: 0.1095 - val_loss: 306.7592 - val_acc: 4.8828e-04\n",
      "Epoch 442/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 327.1964 - acc: 0.0944 - val_loss: 355.9489 - val_acc: 0.2500\n",
      "Epoch 443/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 293.1543 - acc: 0.1204 - val_loss: 272.7350 - val_acc: 0.0051\n",
      "Epoch 444/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 312.7822 - acc: 0.1284 - val_loss: 384.5409 - val_acc: 0.0000e+00\n",
      "Epoch 445/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 318.4962 - acc: 0.0913 - val_loss: 313.4915 - val_acc: 0.0000e+00\n",
      "Epoch 446/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 418.5448 - acc: 0.0797 - val_loss: 412.1022 - val_acc: 0.0012\n",
      "Epoch 447/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 333.6341 - acc: 0.1208 - val_loss: 269.1796 - val_acc: 2.4414e-04\n",
      "Epoch 448/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 415.4648 - acc: 0.0790 - val_loss: 299.0707 - val_acc: 0.0110\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 4us/sample - loss: 409.6974 - acc: 0.1383 - val_loss: 329.8209 - val_acc: 0.0076\n",
      "Epoch 450/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 365.3112 - acc: 0.1054 - val_loss: 412.5522 - val_acc: 0.0034\n",
      "Epoch 451/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 341.8492 - acc: 0.0790 - val_loss: 395.8898 - val_acc: 4.8828e-04\n",
      "Epoch 452/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 402.9918 - acc: 0.0810 - val_loss: 453.4138 - val_acc: 4.8828e-04\n",
      "Epoch 453/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 410.6152 - acc: 0.1326 - val_loss: 349.4256 - val_acc: 2.4414e-04\n",
      "Epoch 454/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 367.6932 - acc: 0.0802 - val_loss: 212.2183 - val_acc: 0.0000e+00\n",
      "Epoch 455/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 269.0878 - acc: 0.0797 - val_loss: 343.4771 - val_acc: 0.6260\n",
      "Epoch 456/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 340.5091 - acc: 0.1144 - val_loss: 349.8394 - val_acc: 0.2361\n",
      "Epoch 457/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 454.3042 - acc: 0.1157 - val_loss: 434.9516 - val_acc: 0.0017\n",
      "Epoch 458/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 387.0811 - acc: 0.0727 - val_loss: 400.5875 - val_acc: 0.0000e+00\n",
      "Epoch 459/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 396.2316 - acc: 0.1059 - val_loss: 345.7818 - val_acc: 0.0012\n",
      "Epoch 460/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 335.3222 - acc: 0.0759 - val_loss: 322.7493 - val_acc: 0.2485\n",
      "Epoch 461/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 347.5809 - acc: 0.1074 - val_loss: 427.0378 - val_acc: 7.3242e-04\n",
      "Epoch 462/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 384.2057 - acc: 0.0828 - val_loss: 503.6743 - val_acc: 0.0229\n",
      "Epoch 463/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 369.0813 - acc: 0.1275 - val_loss: 344.3595 - val_acc: 0.0000e+00\n",
      "Epoch 464/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 438.1045 - acc: 0.0816 - val_loss: 298.2716 - val_acc: 0.0000e+00\n",
      "Epoch 465/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 337.3549 - acc: 0.1091 - val_loss: 411.3801 - val_acc: 7.3242e-04\n",
      "Epoch 466/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 411.3737 - acc: 0.0836 - val_loss: 285.0832 - val_acc: 0.0000e+00\n",
      "Epoch 467/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 331.8466 - acc: 0.1048 - val_loss: 282.8162 - val_acc: 7.3242e-04\n",
      "Epoch 468/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 344.0060 - acc: 0.0833 - val_loss: 319.0237 - val_acc: 0.0356\n",
      "Epoch 469/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 466.9284 - acc: 0.0930 - val_loss: 489.3226 - val_acc: 0.7310\n",
      "Epoch 470/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 516.6758 - acc: 0.1134 - val_loss: 579.0267 - val_acc: 2.4414e-04\n",
      "Epoch 471/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 437.5119 - acc: 0.0965 - val_loss: 394.9336 - val_acc: 0.0000e+00\n",
      "Epoch 472/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 414.2179 - acc: 0.0927 - val_loss: 523.7249 - val_acc: 4.8828e-04\n",
      "Epoch 473/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 405.6381 - acc: 0.1148 - val_loss: 364.8966 - val_acc: 0.0024\n",
      "Epoch 474/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 299.4735 - acc: 0.0839 - val_loss: 334.7467 - val_acc: 0.0044\n",
      "Epoch 475/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 355.9658 - acc: 0.0958 - val_loss: 346.6439 - val_acc: 4.8828e-04\n",
      "Epoch 476/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 489.5020 - acc: 0.1008 - val_loss: 527.6575 - val_acc: 0.0488\n",
      "Epoch 477/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 464.5342 - acc: 0.0874 - val_loss: 405.3490 - val_acc: 0.0000e+00\n",
      "Epoch 478/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 401.6609 - acc: 0.1033 - val_loss: 372.3108 - val_acc: 0.0000e+00\n",
      "Epoch 479/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 310.2931 - acc: 0.0979 - val_loss: 398.9436 - val_acc: 0.0000e+00\n",
      "Epoch 480/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 389.1931 - acc: 0.1290 - val_loss: 432.6519 - val_acc: 0.2483\n",
      "Epoch 481/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 442.6356 - acc: 0.0919 - val_loss: 592.6790 - val_acc: 0.0046\n",
      "Epoch 482/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 386.5288 - acc: 0.0751 - val_loss: 275.5487 - val_acc: 0.0000e+00\n",
      "Epoch 483/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 362.9160 - acc: 0.0833 - val_loss: 541.4191 - val_acc: 0.2490\n",
      "Epoch 484/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 497.9024 - acc: 0.1515 - val_loss: 374.2248 - val_acc: 0.0029\n",
      "Epoch 485/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 481.2993 - acc: 0.0974 - val_loss: 505.6738 - val_acc: 0.0000e+00\n",
      "Epoch 486/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 481.9113 - acc: 0.0821 - val_loss: 437.8064 - val_acc: 0.0000e+00\n",
      "Epoch 487/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 503.0637 - acc: 0.0927 - val_loss: 607.6307 - val_acc: 0.0000e+00\n",
      "Epoch 488/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 498.5671 - acc: 0.1145 - val_loss: 551.2885 - val_acc: 2.4414e-04\n",
      "Epoch 489/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 423.6747 - acc: 0.0855 - val_loss: 471.3487 - val_acc: 0.0020\n",
      "Epoch 490/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 378.2003 - acc: 0.0786 - val_loss: 482.8796 - val_acc: 2.4414e-04\n",
      "Epoch 491/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 419.1440 - acc: 0.1006 - val_loss: 512.9725 - val_acc: 0.0020\n",
      "Epoch 492/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 438.5493 - acc: 0.1421 - val_loss: 348.6490 - val_acc: 2.4414e-04\n",
      "Epoch 493/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 503.4303 - acc: 0.0809 - val_loss: 485.2976 - val_acc: 0.0000e+00\n",
      "Epoch 494/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 436.4218 - acc: 0.0944 - val_loss: 314.5514 - val_acc: 0.0012\n",
      "Epoch 495/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 434.9188 - acc: 0.1055 - val_loss: 357.0810 - val_acc: 4.8828e-04\n",
      "Epoch 496/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 427.4120 - acc: 0.0845 - val_loss: 390.9066 - val_acc: 0.7129\n",
      "Epoch 497/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 424.1209 - acc: 0.1112 - val_loss: 523.9257 - val_acc: 2.4414e-04\n",
      "Epoch 498/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 410.8671 - acc: 0.0807 - val_loss: 449.9520 - val_acc: 0.0093\n",
      "Epoch 499/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 444.7351 - acc: 0.1294 - val_loss: 469.3495 - val_acc: 9.7656e-04\n",
      "Epoch 500/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 565.5513 - acc: 0.0996 - val_loss: 443.5173 - val_acc: 0.2483\n",
      "Epoch 501/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 509.8411 - acc: 0.0978 - val_loss: 402.6960 - val_acc: 2.4414e-04\n",
      "Epoch 502/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 489.8965 - acc: 0.1117 - val_loss: 601.5578 - val_acc: 0.0027\n",
      "Epoch 503/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 517.4266 - acc: 0.0726 - val_loss: 349.0394 - val_acc: 7.3242e-04\n",
      "Epoch 504/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 4us/sample - loss: 494.9797 - acc: 0.1052 - val_loss: 662.2170 - val_acc: 4.8828e-04\n",
      "Epoch 505/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 412.0205 - acc: 0.0982 - val_loss: 566.2265 - val_acc: 2.4414e-04\n",
      "Epoch 506/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 536.3795 - acc: 0.1087 - val_loss: 561.1865 - val_acc: 4.8828e-04\n",
      "Epoch 507/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 478.1276 - acc: 0.0819 - val_loss: 534.0735 - val_acc: 7.3242e-04\n",
      "Epoch 508/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 453.3953 - acc: 0.1140 - val_loss: 465.2303 - val_acc: 0.0000e+00\n",
      "Epoch 509/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 404.3840 - acc: 0.0900 - val_loss: 401.8851 - val_acc: 0.0017\n",
      "Epoch 510/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 544.6651 - acc: 0.1031 - val_loss: 496.2090 - val_acc: 0.0000e+00\n",
      "Epoch 511/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 476.1277 - acc: 0.0844 - val_loss: 556.6525 - val_acc: 0.0020\n",
      "Epoch 512/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 584.0563 - acc: 0.0955 - val_loss: 578.2981 - val_acc: 0.0144\n",
      "Epoch 513/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 512.0204 - acc: 0.1377 - val_loss: 519.1897 - val_acc: 2.4414e-04\n",
      "Epoch 514/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 407.9693 - acc: 0.0707 - val_loss: 583.7363 - val_acc: 0.0000e+00\n",
      "Epoch 515/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 390.5775 - acc: 0.0903 - val_loss: 387.8344 - val_acc: 2.4414e-04\n",
      "Epoch 516/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 459.0151 - acc: 0.0782 - val_loss: 456.8745 - val_acc: 0.7229\n",
      "Epoch 517/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 538.2458 - acc: 0.1086 - val_loss: 411.2097 - val_acc: 0.0095\n",
      "Epoch 518/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 502.0841 - acc: 0.1299 - val_loss: 735.3464 - val_acc: 0.0000e+00\n",
      "Epoch 519/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 580.2288 - acc: 0.0800 - val_loss: 484.3743 - val_acc: 0.0085\n",
      "Epoch 520/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 512.2768 - acc: 0.0995 - val_loss: 364.5148 - val_acc: 2.4414e-04\n",
      "Epoch 521/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 527.7169 - acc: 0.1099 - val_loss: 577.2295 - val_acc: 0.0000e+00\n",
      "Epoch 522/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 536.4652 - acc: 0.0791 - val_loss: 521.5721 - val_acc: 7.3242e-04\n",
      "Epoch 523/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 513.5199 - acc: 0.0892 - val_loss: 445.7140 - val_acc: 0.2578\n",
      "Epoch 524/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 550.5287 - acc: 0.1345 - val_loss: 501.5338 - val_acc: 0.0012\n",
      "Epoch 525/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 423.4841 - acc: 0.0868 - val_loss: 462.5262 - val_acc: 2.4414e-04\n",
      "Epoch 526/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 388.9448 - acc: 0.1007 - val_loss: 557.7602 - val_acc: 4.8828e-04\n",
      "Epoch 527/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 533.5094 - acc: 0.0907 - val_loss: 364.8665 - val_acc: 4.8828e-04\n",
      "Epoch 528/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 503.0856 - acc: 0.0991 - val_loss: 570.8933 - val_acc: 0.7009\n",
      "Epoch 529/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 494.1913 - acc: 0.1030 - val_loss: 430.8413 - val_acc: 0.0000e+00\n",
      "Epoch 530/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 393.5953 - acc: 0.0876 - val_loss: 518.2091 - val_acc: 7.3242e-04\n",
      "Epoch 531/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 469.4735 - acc: 0.0978 - val_loss: 598.4860 - val_acc: 0.0054\n",
      "Epoch 532/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 464.3294 - acc: 0.1113 - val_loss: 319.8441 - val_acc: 0.0012\n",
      "Epoch 533/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 437.5026 - acc: 0.0819 - val_loss: 567.7240 - val_acc: 0.0093\n",
      "Epoch 534/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 457.9007 - acc: 0.1118 - val_loss: 416.3760 - val_acc: 0.6414\n",
      "Epoch 535/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 541.6044 - acc: 0.1071 - val_loss: 729.3906 - val_acc: 0.0027\n",
      "Epoch 536/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 530.1353 - acc: 0.1057 - val_loss: 514.7839 - val_acc: 0.0000e+00\n",
      "Epoch 537/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 581.9944 - acc: 0.0800 - val_loss: 543.6694 - val_acc: 7.3242e-04\n",
      "Epoch 538/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 501.7371 - acc: 0.1088 - val_loss: 415.9170 - val_acc: 0.0015\n",
      "Epoch 539/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 419.7310 - acc: 0.1021 - val_loss: 733.6315 - val_acc: 2.4414e-04\n",
      "Epoch 540/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 679.7532 - acc: 0.1113 - val_loss: 562.0261 - val_acc: 0.0000e+00\n",
      "Epoch 541/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 557.6753 - acc: 0.0838 - val_loss: 567.3072 - val_acc: 0.0046\n",
      "Epoch 542/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 521.9663 - acc: 0.1065 - val_loss: 560.8286 - val_acc: 2.4414e-04\n",
      "Epoch 543/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 528.3667 - acc: 0.0726 - val_loss: 515.8611 - val_acc: 4.8828e-04\n",
      "Epoch 544/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 510.9558 - acc: 0.1371 - val_loss: 540.0050 - val_acc: 2.4414e-04\n",
      "Epoch 545/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 557.7936 - acc: 0.0816 - val_loss: 595.6721 - val_acc: 0.2485\n",
      "Epoch 546/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 514.2611 - acc: 0.0822 - val_loss: 325.7009 - val_acc: 9.7656e-04\n",
      "Epoch 547/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 420.8703 - acc: 0.1056 - val_loss: 534.2822 - val_acc: 0.0000e+00\n",
      "Epoch 548/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 544.1567 - acc: 0.0915 - val_loss: 487.4340 - val_acc: 0.0063\n",
      "Epoch 549/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 586.6839 - acc: 0.1196 - val_loss: 516.4148 - val_acc: 0.0017\n",
      "Epoch 550/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 597.0514 - acc: 0.0939 - val_loss: 770.5349 - val_acc: 0.0000e+00\n",
      "Epoch 551/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 674.0277 - acc: 0.1001 - val_loss: 486.7019 - val_acc: 0.0042\n",
      "Epoch 552/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 510.3244 - acc: 0.0715 - val_loss: 573.9212 - val_acc: 0.0000e+00\n",
      "Epoch 553/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 528.2596 - acc: 0.1237 - val_loss: 886.1760 - val_acc: 7.3242e-04\n",
      "Epoch 554/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 642.6506 - acc: 0.0898 - val_loss: 556.3376 - val_acc: 0.2490\n",
      "Epoch 555/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 525.2324 - acc: 0.0947 - val_loss: 433.3405 - val_acc: 2.4414e-04\n",
      "Epoch 556/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 528.6406 - acc: 0.0814 - val_loss: 590.1786 - val_acc: 0.0012\n",
      "Epoch 557/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 575.7862 - acc: 0.1163 - val_loss: 765.7640 - val_acc: 0.2485\n",
      "Epoch 558/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 593.6065 - acc: 0.1187 - val_loss: 697.4547 - val_acc: 4.8828e-04\n",
      "Epoch 559/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 4us/sample - loss: 652.5954 - acc: 0.0812 - val_loss: 582.5560 - val_acc: 0.0000e+00\n",
      "Epoch 560/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 649.8324 - acc: 0.0838 - val_loss: 696.7987 - val_acc: 0.2495\n",
      "Epoch 561/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 584.3796 - acc: 0.1479 - val_loss: 646.4854 - val_acc: 0.0000e+00\n",
      "Epoch 562/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 571.5419 - acc: 0.0782 - val_loss: 633.3179 - val_acc: 0.0000e+00\n",
      "Epoch 563/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 635.0643 - acc: 0.0904 - val_loss: 470.9619 - val_acc: 0.2537\n",
      "Epoch 564/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 674.8175 - acc: 0.1008 - val_loss: 480.5544 - val_acc: 0.0015\n",
      "Epoch 565/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 550.8778 - acc: 0.1013 - val_loss: 453.2704 - val_acc: 9.7656e-04\n",
      "Epoch 566/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 482.8944 - acc: 0.0814 - val_loss: 608.4925 - val_acc: 2.4414e-04\n",
      "Epoch 567/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 607.8050 - acc: 0.0934 - val_loss: 446.4413 - val_acc: 9.7656e-04\n",
      "Epoch 568/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 527.0651 - acc: 0.1175 - val_loss: 591.4068 - val_acc: 4.8828e-04\n",
      "Epoch 569/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 610.2815 - acc: 0.0749 - val_loss: 693.8396 - val_acc: 4.8828e-04\n",
      "Epoch 570/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 647.5356 - acc: 0.1192 - val_loss: 379.2047 - val_acc: 0.0034\n",
      "Epoch 571/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 559.6428 - acc: 0.0910 - val_loss: 607.8312 - val_acc: 0.0000e+00\n",
      "Epoch 572/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 535.9334 - acc: 0.1201 - val_loss: 513.0777 - val_acc: 4.8828e-04\n",
      "Epoch 573/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 471.0680 - acc: 0.0879 - val_loss: 435.4893 - val_acc: 0.0012\n",
      "Epoch 574/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 531.9628 - acc: 0.0778 - val_loss: 802.2147 - val_acc: 0.0320\n",
      "Epoch 575/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 650.0902 - acc: 0.1238 - val_loss: 916.8466 - val_acc: 0.0000e+00\n",
      "Epoch 576/1000\n",
      "12286/12286 [==============================] - 0s 6us/sample - loss: 788.1967 - acc: 0.0809 - val_loss: 573.8661 - val_acc: 4.8828e-04\n",
      "Epoch 577/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 633.6245 - acc: 0.1135 - val_loss: 735.5294 - val_acc: 7.3242e-04\n",
      "Epoch 578/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 525.5497 - acc: 0.1003 - val_loss: 464.8767 - val_acc: 0.0137\n",
      "Epoch 579/1000\n",
      "12286/12286 [==============================] - 0s 6us/sample - loss: 560.1417 - acc: 0.1225 - val_loss: 433.2374 - val_acc: 4.8828e-04\n",
      "Epoch 580/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 503.7065 - acc: 0.0961 - val_loss: 665.5331 - val_acc: 0.0000e+00\n",
      "Epoch 581/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 569.0542 - acc: 0.0814 - val_loss: 645.4827 - val_acc: 0.0000e+00\n",
      "Epoch 582/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 512.8161 - acc: 0.1136 - val_loss: 509.5786 - val_acc: 7.3242e-04\n",
      "Epoch 583/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 490.1121 - acc: 0.1201 - val_loss: 474.2564 - val_acc: 0.0000e+00\n",
      "Epoch 584/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 581.8526 - acc: 0.0789 - val_loss: 326.4944 - val_acc: 0.0000e+00\n",
      "Epoch 585/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 523.3416 - acc: 0.0848 - val_loss: 571.3393 - val_acc: 4.8828e-04\n",
      "Epoch 586/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 611.9315 - acc: 0.1210 - val_loss: 740.3231 - val_acc: 7.3242e-04\n",
      "Epoch 587/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 544.6659 - acc: 0.0852 - val_loss: 433.8932 - val_acc: 0.0020\n",
      "Epoch 588/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 596.9117 - acc: 0.1236 - val_loss: 526.5551 - val_acc: 0.6382\n",
      "Epoch 589/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 525.6322 - acc: 0.0818 - val_loss: 626.0931 - val_acc: 0.7307\n",
      "Epoch 590/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 608.1001 - acc: 0.1156 - val_loss: 733.9741 - val_acc: 0.0012\n",
      "Epoch 591/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 571.7755 - acc: 0.0943 - val_loss: 360.6015 - val_acc: 0.0059\n",
      "Epoch 592/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 533.1587 - acc: 0.1144 - val_loss: 654.3475 - val_acc: 0.0000e+00\n",
      "Epoch 593/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 586.8720 - acc: 0.0820 - val_loss: 804.4434 - val_acc: 0.0034\n",
      "Epoch 594/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 593.1311 - acc: 0.1203 - val_loss: 541.1874 - val_acc: 7.3242e-04\n",
      "Epoch 595/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 615.4017 - acc: 0.1074 - val_loss: 501.0137 - val_acc: 2.4414e-04\n",
      "Epoch 596/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 451.6654 - acc: 0.0843 - val_loss: 267.9315 - val_acc: 0.0125\n",
      "Epoch 597/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 562.3884 - acc: 0.0851 - val_loss: 552.4670 - val_acc: 0.2495\n",
      "Epoch 598/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 635.9550 - acc: 0.1234 - val_loss: 655.3827 - val_acc: 4.8828e-04\n",
      "Epoch 599/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 620.2788 - acc: 0.0735 - val_loss: 555.7722 - val_acc: 0.7383\n",
      "Epoch 600/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 589.8535 - acc: 0.1095 - val_loss: 703.1732 - val_acc: 0.2500\n",
      "Epoch 601/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 725.7956 - acc: 0.0932 - val_loss: 638.2265 - val_acc: 0.7292\n",
      "Epoch 602/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 597.2090 - acc: 0.0940 - val_loss: 612.7734 - val_acc: 0.7246\n",
      "Epoch 603/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 570.7348 - acc: 0.1236 - val_loss: 526.4513 - val_acc: 0.0012\n",
      "Epoch 604/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 559.8913 - acc: 0.0992 - val_loss: 555.6655 - val_acc: 4.8828e-04\n",
      "Epoch 605/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 585.5665 - acc: 0.0737 - val_loss: 462.5574 - val_acc: 2.4414e-04\n",
      "Epoch 606/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 499.0279 - acc: 0.0969 - val_loss: 692.7190 - val_acc: 0.0029\n",
      "Epoch 607/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 634.0779 - acc: 0.1126 - val_loss: 737.4200 - val_acc: 0.0037\n",
      "Epoch 608/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 662.8120 - acc: 0.0801 - val_loss: 523.6638 - val_acc: 4.8828e-04\n",
      "Epoch 609/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 720.3475 - acc: 0.0893 - val_loss: 785.6144 - val_acc: 2.4414e-04\n",
      "Epoch 610/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 587.4308 - acc: 0.0943 - val_loss: 753.8023 - val_acc: 0.7324\n",
      "Epoch 611/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 741.2424 - acc: 0.1095 - val_loss: 616.9510 - val_acc: 0.7251\n",
      "Epoch 612/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 681.5226 - acc: 0.1168 - val_loss: 905.7441 - val_acc: 2.4414e-04\n",
      "Epoch 613/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 669.4031 - acc: 0.0873 - val_loss: 756.0401 - val_acc: 0.0027\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 4us/sample - loss: 625.4726 - acc: 0.0987 - val_loss: 659.9855 - val_acc: 0.7380\n",
      "Epoch 615/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 581.5334 - acc: 0.1075 - val_loss: 718.8950 - val_acc: 0.0000e+00\n",
      "Epoch 616/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 592.6755 - acc: 0.0951 - val_loss: 668.3535 - val_acc: 4.8828e-04\n",
      "Epoch 617/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 582.4221 - acc: 0.0736 - val_loss: 610.6414 - val_acc: 0.0017\n",
      "Epoch 618/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 654.3711 - acc: 0.1223 - val_loss: 668.2047 - val_acc: 0.0105\n",
      "Epoch 619/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 697.8014 - acc: 0.1377 - val_loss: 592.4893 - val_acc: 0.0037\n",
      "Epoch 620/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 713.0297 - acc: 0.0576 - val_loss: 651.8153 - val_acc: 0.0078\n",
      "Epoch 621/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 588.6497 - acc: 0.1175 - val_loss: 761.7015 - val_acc: 0.0095\n",
      "Epoch 622/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 673.6650 - acc: 0.0938 - val_loss: 630.5360 - val_acc: 2.4414e-04\n",
      "Epoch 623/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 661.2624 - acc: 0.0825 - val_loss: 678.1492 - val_acc: 0.0081\n",
      "Epoch 624/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 635.8483 - acc: 0.1113 - val_loss: 504.9348 - val_acc: 2.4414e-04\n",
      "Epoch 625/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 613.9745 - acc: 0.1029 - val_loss: 906.6603 - val_acc: 0.0012\n",
      "Epoch 626/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 717.6380 - acc: 0.0801 - val_loss: 620.1596 - val_acc: 0.2449\n",
      "Epoch 627/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 679.3053 - acc: 0.1342 - val_loss: 668.0540 - val_acc: 4.8828e-04\n",
      "Epoch 628/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 574.4565 - acc: 0.0580 - val_loss: 588.5893 - val_acc: 0.7419\n",
      "Epoch 629/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 607.8317 - acc: 0.1125 - val_loss: 723.9156 - val_acc: 0.2500\n",
      "Epoch 630/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 741.4783 - acc: 0.0909 - val_loss: 522.6476 - val_acc: 7.3242e-04\n",
      "Epoch 631/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 566.4855 - acc: 0.1446 - val_loss: 679.1565 - val_acc: 2.4414e-04\n",
      "Epoch 632/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 602.5264 - acc: 0.0918 - val_loss: 747.6002 - val_acc: 0.0000e+00\n",
      "Epoch 633/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 643.2877 - acc: 0.0805 - val_loss: 609.4237 - val_acc: 4.8828e-04\n",
      "Epoch 634/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 661.9749 - acc: 0.0965 - val_loss: 939.3680 - val_acc: 2.4414e-04\n",
      "Epoch 635/1000\n",
      "12286/12286 [==============================] - 0s 6us/sample - loss: 685.8826 - acc: 0.0962 - val_loss: 686.5978 - val_acc: 0.7427\n",
      "Epoch 636/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 683.7610 - acc: 0.1131 - val_loss: 601.5015 - val_acc: 0.0034\n",
      "Epoch 637/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 687.8079 - acc: 0.1122 - val_loss: 593.2516 - val_acc: 4.8828e-04\n",
      "Epoch 638/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 593.1668 - acc: 0.0803 - val_loss: 569.5876 - val_acc: 4.8828e-04\n",
      "Epoch 639/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 656.5419 - acc: 0.1130 - val_loss: 752.8142 - val_acc: 0.0039\n",
      "Epoch 640/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 637.9976 - acc: 0.1132 - val_loss: 559.0653 - val_acc: 0.0000e+00\n",
      "Epoch 641/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 660.5206 - acc: 0.0770 - val_loss: 779.9231 - val_acc: 4.8828e-04\n",
      "Epoch 642/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 720.4713 - acc: 0.0912 - val_loss: 724.5856 - val_acc: 0.0000e+00\n",
      "Epoch 643/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 686.8974 - acc: 0.1272 - val_loss: 835.4369 - val_acc: 4.8828e-04\n",
      "Epoch 644/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 617.5899 - acc: 0.0835 - val_loss: 705.7183 - val_acc: 0.0046\n",
      "Epoch 645/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 647.4400 - acc: 0.0991 - val_loss: 467.8455 - val_acc: 0.0046\n",
      "Epoch 646/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 721.6050 - acc: 0.0829 - val_loss: 864.6235 - val_acc: 4.8828e-04\n",
      "Epoch 647/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 788.2169 - acc: 0.1253 - val_loss: 742.3053 - val_acc: 2.4414e-04\n",
      "Epoch 648/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 618.5196 - acc: 0.0928 - val_loss: 378.4855 - val_acc: 0.0000e+00\n",
      "Epoch 649/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 577.2275 - acc: 0.0816 - val_loss: 709.7172 - val_acc: 4.8828e-04\n",
      "Epoch 650/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 659.2228 - acc: 0.0819 - val_loss: 610.6522 - val_acc: 0.0059\n",
      "Epoch 651/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 569.0261 - acc: 0.1142 - val_loss: 617.7166 - val_acc: 4.8828e-04\n",
      "Epoch 652/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 727.8196 - acc: 0.1188 - val_loss: 810.1947 - val_acc: 2.4414e-04\n",
      "Epoch 653/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 704.7813 - acc: 0.0799 - val_loss: 645.1493 - val_acc: 7.3242e-04\n",
      "Epoch 654/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 614.3835 - acc: 0.1079 - val_loss: 802.6784 - val_acc: 2.4414e-04\n",
      "Epoch 655/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 637.0554 - acc: 0.0798 - val_loss: 674.5261 - val_acc: 2.4414e-04\n",
      "Epoch 656/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 774.9587 - acc: 0.1118 - val_loss: 530.3191 - val_acc: 4.8828e-04\n",
      "Epoch 657/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 736.8642 - acc: 0.1047 - val_loss: 678.8476 - val_acc: 0.2488\n",
      "Epoch 658/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 841.6381 - acc: 0.1012 - val_loss: 973.4742 - val_acc: 0.0000e+00\n",
      "Epoch 659/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 802.2114 - acc: 0.0748 - val_loss: 635.3427 - val_acc: 0.0000e+00\n",
      "Epoch 660/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 737.9189 - acc: 0.1140 - val_loss: 878.4453 - val_acc: 2.4414e-04\n",
      "Epoch 661/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 657.2781 - acc: 0.0739 - val_loss: 795.1234 - val_acc: 0.2495\n",
      "Epoch 662/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 714.6688 - acc: 0.1112 - val_loss: 1017.0259 - val_acc: 0.2483\n",
      "Epoch 663/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 769.3157 - acc: 0.0930 - val_loss: 773.3218 - val_acc: 0.0146\n",
      "Epoch 664/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 769.7085 - acc: 0.1213 - val_loss: 619.8464 - val_acc: 4.8828e-04\n",
      "Epoch 665/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 774.7834 - acc: 0.0808 - val_loss: 910.1155 - val_acc: 0.0012\n",
      "Epoch 666/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 811.4513 - acc: 0.1195 - val_loss: 893.3859 - val_acc: 7.3242e-04\n",
      "Epoch 667/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 670.9512 - acc: 0.1172 - val_loss: 659.9249 - val_acc: 0.0208\n",
      "Epoch 668/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 858.3309 - acc: 0.0781 - val_loss: 997.7388 - val_acc: 2.4414e-04\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 4us/sample - loss: 875.8280 - acc: 0.0865 - val_loss: 1058.0397 - val_acc: 0.0029\n",
      "Epoch 670/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 968.1111 - acc: 0.0839 - val_loss: 831.9666 - val_acc: 0.0000e+00\n",
      "Epoch 671/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 827.4685 - acc: 0.1184 - val_loss: 915.9357 - val_acc: 0.0078\n",
      "Epoch 672/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 739.4248 - acc: 0.0878 - val_loss: 833.1333 - val_acc: 9.7656e-04\n",
      "Epoch 673/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 645.8679 - acc: 0.1059 - val_loss: 558.0202 - val_acc: 0.0000e+00\n",
      "Epoch 674/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 732.4871 - acc: 0.1103 - val_loss: 768.4919 - val_acc: 2.4414e-04\n",
      "Epoch 675/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 768.1548 - acc: 0.0912 - val_loss: 701.3705 - val_acc: 0.0000e+00\n",
      "Epoch 676/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 906.3562 - acc: 0.0810 - val_loss: 886.1578 - val_acc: 0.2490\n",
      "Epoch 677/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 859.8988 - acc: 0.1206 - val_loss: 978.1332 - val_acc: 0.2468\n",
      "Epoch 678/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 865.2051 - acc: 0.0855 - val_loss: 699.0369 - val_acc: 0.0032\n",
      "Epoch 679/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 753.4866 - acc: 0.1253 - val_loss: 801.2704 - val_acc: 0.0032\n",
      "Epoch 680/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 724.6514 - acc: 0.0908 - val_loss: 741.6551 - val_acc: 0.0000e+00\n",
      "Epoch 681/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 748.2190 - acc: 0.0845 - val_loss: 565.4482 - val_acc: 0.7078\n",
      "Epoch 682/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 576.5861 - acc: 0.1144 - val_loss: 659.9635 - val_acc: 0.0000e+00\n",
      "Epoch 683/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 675.9617 - acc: 0.0763 - val_loss: 724.0031 - val_acc: 0.7400\n",
      "Epoch 684/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 757.2228 - acc: 0.1228 - val_loss: 769.7433 - val_acc: 0.0000e+00\n",
      "Epoch 685/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 691.3823 - acc: 0.0701 - val_loss: 818.5737 - val_acc: 0.7407\n",
      "Epoch 686/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 701.0152 - acc: 0.1095 - val_loss: 692.3675 - val_acc: 0.2493\n",
      "Epoch 687/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 701.8183 - acc: 0.0978 - val_loss: 765.6894 - val_acc: 0.6968\n",
      "Epoch 688/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 868.0005 - acc: 0.1072 - val_loss: 1104.5619 - val_acc: 0.0000e+00\n",
      "Epoch 689/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 824.3799 - acc: 0.1012 - val_loss: 748.0178 - val_acc: 0.1453\n",
      "Epoch 690/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 677.7762 - acc: 0.1199 - val_loss: 897.6870 - val_acc: 0.0000e+00\n",
      "Epoch 691/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 801.1056 - acc: 0.0794 - val_loss: 882.4968 - val_acc: 0.0000e+00\n",
      "Epoch 692/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 951.2074 - acc: 0.0872 - val_loss: 834.6166 - val_acc: 4.8828e-04\n",
      "Epoch 693/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 703.0797 - acc: 0.1236 - val_loss: 767.2031 - val_acc: 0.0039\n",
      "Epoch 694/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 612.9460 - acc: 0.0805 - val_loss: 621.5823 - val_acc: 0.0015\n",
      "Epoch 695/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 777.8674 - acc: 0.1271 - val_loss: 771.6385 - val_acc: 0.0000e+00\n",
      "Epoch 696/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 941.7847 - acc: 0.0803 - val_loss: 836.3458 - val_acc: 0.0000e+00\n",
      "Epoch 697/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 836.8033 - acc: 0.1105 - val_loss: 791.9899 - val_acc: 4.8828e-04\n",
      "Epoch 698/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 855.1830 - acc: 0.1096 - val_loss: 907.4793 - val_acc: 0.0044\n",
      "Epoch 699/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 888.2731 - acc: 0.0986 - val_loss: 842.2730 - val_acc: 4.8828e-04\n",
      "Epoch 700/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 835.0820 - acc: 0.0955 - val_loss: 921.3908 - val_acc: 4.8828e-04\n",
      "Epoch 701/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 834.0420 - acc: 0.0836 - val_loss: 850.3737 - val_acc: 0.2505\n",
      "Epoch 702/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 991.3729 - acc: 0.1199 - val_loss: 801.2809 - val_acc: 0.0020\n",
      "Epoch 703/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 887.1155 - acc: 0.1263 - val_loss: 584.6120 - val_acc: 0.0459\n",
      "Epoch 704/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 776.9218 - acc: 0.0819 - val_loss: 760.1664 - val_acc: 2.4414e-04\n",
      "Epoch 705/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 709.7077 - acc: 0.1112 - val_loss: 749.1673 - val_acc: 4.8828e-04\n",
      "Epoch 706/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 769.8653 - acc: 0.0828 - val_loss: 661.7428 - val_acc: 0.7271\n",
      "Epoch 707/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 796.7246 - acc: 0.1108 - val_loss: 765.3431 - val_acc: 2.4414e-04\n",
      "Epoch 708/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 924.1357 - acc: 0.0864 - val_loss: 962.9102 - val_acc: 0.0042\n",
      "Epoch 709/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 915.3039 - acc: 0.1437 - val_loss: 845.9141 - val_acc: 0.0000e+00\n",
      "Epoch 710/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 709.6925 - acc: 0.0909 - val_loss: 857.2666 - val_acc: 0.0000e+00\n",
      "Epoch 711/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 742.0370 - acc: 0.0992 - val_loss: 813.8236 - val_acc: 2.4414e-04\n",
      "Epoch 712/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 662.0374 - acc: 0.0718 - val_loss: 637.7026 - val_acc: 7.3242e-04\n",
      "Epoch 713/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 664.8806 - acc: 0.1513 - val_loss: 916.7314 - val_acc: 0.0000e+00\n",
      "Epoch 714/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 771.2230 - acc: 0.0812 - val_loss: 739.7710 - val_acc: 0.0000e+00\n",
      "Epoch 715/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 890.6568 - acc: 0.0757 - val_loss: 743.5123 - val_acc: 2.4414e-04\n",
      "Epoch 716/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 905.5583 - acc: 0.1239 - val_loss: 850.6604 - val_acc: 0.0068\n",
      "Epoch 717/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 958.8387 - acc: 0.0808 - val_loss: 935.7273 - val_acc: 0.0012\n",
      "Epoch 718/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 780.2587 - acc: 0.1224 - val_loss: 727.0850 - val_acc: 7.3242e-04\n",
      "Epoch 719/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 745.8975 - acc: 0.0857 - val_loss: 674.8391 - val_acc: 0.2495\n",
      "Epoch 720/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 830.9691 - acc: 0.1069 - val_loss: 681.7860 - val_acc: 0.0000e+00\n",
      "Epoch 721/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 936.0879 - acc: 0.0821 - val_loss: 1318.3685 - val_acc: 2.4414e-04\n",
      "Epoch 722/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 877.2163 - acc: 0.1328 - val_loss: 680.5244 - val_acc: 0.0000e+00\n",
      "Epoch 723/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 873.5772 - acc: 0.0817 - val_loss: 1123.1781 - val_acc: 0.0105\n",
      "Epoch 724/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 4us/sample - loss: 998.3573 - acc: 0.0964 - val_loss: 989.9041 - val_acc: 7.3242e-04\n",
      "Epoch 725/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 935.0962 - acc: 0.1420 - val_loss: 832.6917 - val_acc: 2.4414e-04\n",
      "Epoch 726/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 775.8719 - acc: 0.0824 - val_loss: 769.4144 - val_acc: 2.4414e-04\n",
      "Epoch 727/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 826.4379 - acc: 0.0765 - val_loss: 1363.6724 - val_acc: 0.0000e+00\n",
      "Epoch 728/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 920.9221 - acc: 0.0906 - val_loss: 540.0223 - val_acc: 0.0046\n",
      "Epoch 729/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 783.2311 - acc: 0.1235 - val_loss: 1019.7088 - val_acc: 0.0032\n",
      "Epoch 730/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 860.4781 - acc: 0.0925 - val_loss: 784.4739 - val_acc: 0.7322\n",
      "Epoch 731/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 796.5983 - acc: 0.1077 - val_loss: 752.1630 - val_acc: 4.8828e-04\n",
      "Epoch 732/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 805.9535 - acc: 0.0908 - val_loss: 730.4034 - val_acc: 0.0017\n",
      "Epoch 733/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 764.6012 - acc: 0.1205 - val_loss: 1123.1193 - val_acc: 7.3242e-04\n",
      "Epoch 734/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 951.4751 - acc: 0.1269 - val_loss: 1143.4823 - val_acc: 0.0022\n",
      "Epoch 735/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 882.7328 - acc: 0.0831 - val_loss: 960.7994 - val_acc: 0.0000e+00\n",
      "Epoch 736/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 741.5270 - acc: 0.0776 - val_loss: 957.6825 - val_acc: 0.7139\n",
      "Epoch 737/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 941.6578 - acc: 0.1018 - val_loss: 1071.2045 - val_acc: 0.2498\n",
      "Epoch 738/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1051.4110 - acc: 0.1369 - val_loss: 736.8744 - val_acc: 2.4414e-04\n",
      "Epoch 739/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1030.5574 - acc: 0.0832 - val_loss: 855.7708 - val_acc: 0.2498\n",
      "Epoch 740/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 947.1179 - acc: 0.0932 - val_loss: 830.2010 - val_acc: 0.7332\n",
      "Epoch 741/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1044.1652 - acc: 0.1105 - val_loss: 972.1533 - val_acc: 0.0039\n",
      "Epoch 742/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 937.2689 - acc: 0.0881 - val_loss: 876.6227 - val_acc: 0.0017\n",
      "Epoch 743/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 796.3671 - acc: 0.1123 - val_loss: 1019.9413 - val_acc: 0.0029\n",
      "Epoch 744/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 898.0394 - acc: 0.0908 - val_loss: 956.4961 - val_acc: 4.8828e-04\n",
      "Epoch 745/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 815.4652 - acc: 0.1025 - val_loss: 778.1122 - val_acc: 2.4414e-04\n",
      "Epoch 746/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 851.2169 - acc: 0.0888 - val_loss: 951.8794 - val_acc: 0.0000e+00\n",
      "Epoch 747/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 756.3039 - acc: 0.0960 - val_loss: 647.1993 - val_acc: 0.0015\n",
      "Epoch 748/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 707.5955 - acc: 0.0711 - val_loss: 648.9283 - val_acc: 0.2515\n",
      "Epoch 749/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 677.6458 - acc: 0.1259 - val_loss: 579.4295 - val_acc: 0.0037\n",
      "Epoch 750/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 567.9129 - acc: 0.0937 - val_loss: 733.7231 - val_acc: 4.8828e-04\n",
      "Epoch 751/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 835.7005 - acc: 0.1280 - val_loss: 1019.1059 - val_acc: 0.0000e+00\n",
      "Epoch 752/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 965.5525 - acc: 0.0889 - val_loss: 754.5875 - val_acc: 9.7656e-04\n",
      "Epoch 753/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 796.7737 - acc: 0.0816 - val_loss: 841.2991 - val_acc: 0.0000e+00\n",
      "Epoch 754/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 953.4859 - acc: 0.1132 - val_loss: 1117.4415 - val_acc: 2.4414e-04\n",
      "Epoch 755/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1087.3005 - acc: 0.0917 - val_loss: 887.9016 - val_acc: 7.3242e-04\n",
      "Epoch 756/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 873.0991 - acc: 0.1000 - val_loss: 693.7599 - val_acc: 2.4414e-04\n",
      "Epoch 757/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 865.3022 - acc: 0.0805 - val_loss: 897.4346 - val_acc: 0.0056\n",
      "Epoch 758/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 950.3789 - acc: 0.1087 - val_loss: 1053.7457 - val_acc: 9.7656e-04\n",
      "Epoch 759/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 886.1045 - acc: 0.1280 - val_loss: 720.2068 - val_acc: 9.7656e-04\n",
      "Epoch 760/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 843.7608 - acc: 0.1088 - val_loss: 834.6772 - val_acc: 0.0000e+00\n",
      "Epoch 761/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 833.4025 - acc: 0.0826 - val_loss: 839.0346 - val_acc: 0.0029\n",
      "Epoch 762/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 910.7780 - acc: 0.0925 - val_loss: 816.3204 - val_acc: 9.7656e-04\n",
      "Epoch 763/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 866.4087 - acc: 0.0872 - val_loss: 1308.4781 - val_acc: 0.7529\n",
      "Epoch 764/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1102.6559 - acc: 0.1279 - val_loss: 925.0114 - val_acc: 2.4414e-04\n",
      "Epoch 765/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 899.1833 - acc: 0.0809 - val_loss: 717.6312 - val_acc: 0.2498\n",
      "Epoch 766/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 852.7033 - acc: 0.1312 - val_loss: 582.9312 - val_acc: 0.0000e+00\n",
      "Epoch 767/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 795.2720 - acc: 0.0806 - val_loss: 1065.5661 - val_acc: 7.3242e-04\n",
      "Epoch 768/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 879.8326 - acc: 0.1118 - val_loss: 993.0296 - val_acc: 2.4414e-04\n",
      "Epoch 769/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1003.7872 - acc: 0.0967 - val_loss: 865.0103 - val_acc: 2.4414e-04\n",
      "Epoch 770/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 893.4633 - acc: 0.1076 - val_loss: 1269.2656 - val_acc: 0.0000e+00\n",
      "Epoch 771/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 801.6001 - acc: 0.0875 - val_loss: 766.6571 - val_acc: 0.0000e+00\n",
      "Epoch 772/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 804.6354 - acc: 0.1205 - val_loss: 1057.7483 - val_acc: 7.3242e-04\n",
      "Epoch 773/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1015.8065 - acc: 0.1212 - val_loss: 1121.5723 - val_acc: 0.0000e+00\n",
      "Epoch 774/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1162.3195 - acc: 0.0799 - val_loss: 1169.1961 - val_acc: 0.0000e+00\n",
      "Epoch 775/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1044.2440 - acc: 0.1017 - val_loss: 992.2581 - val_acc: 4.8828e-04\n",
      "Epoch 776/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 835.0881 - acc: 0.0925 - val_loss: 863.9675 - val_acc: 0.0000e+00\n",
      "Epoch 777/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 868.9211 - acc: 0.0868 - val_loss: 1018.4791 - val_acc: 0.0000e+00\n",
      "Epoch 778/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1044.2388 - acc: 0.1238 - val_loss: 1020.0183 - val_acc: 4.8828e-04\n",
      "Epoch 779/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 5us/sample - loss: 889.6239 - acc: 0.0753 - val_loss: 1038.6107 - val_acc: 0.7197\n",
      "Epoch 780/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 841.7987 - acc: 0.1172 - val_loss: 964.0503 - val_acc: 0.0000e+00\n",
      "Epoch 781/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1012.3272 - acc: 0.0985 - val_loss: 1013.8761 - val_acc: 0.0146\n",
      "Epoch 782/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 843.5021 - acc: 0.0917 - val_loss: 432.8610 - val_acc: 0.6877\n",
      "Epoch 783/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 590.5507 - acc: 0.1170 - val_loss: 673.9417 - val_acc: 0.0083\n",
      "Epoch 784/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 707.7322 - acc: 0.0893 - val_loss: 811.1128 - val_acc: 2.4414e-04\n",
      "Epoch 785/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 960.6601 - acc: 0.1309 - val_loss: 848.5715 - val_acc: 0.0027\n",
      "Epoch 786/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 807.7533 - acc: 0.0837 - val_loss: 592.1051 - val_acc: 7.3242e-04\n",
      "Epoch 787/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 753.7188 - acc: 0.0816 - val_loss: 841.9899 - val_acc: 0.2498\n",
      "Epoch 788/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 749.6396 - acc: 0.0934 - val_loss: 846.1935 - val_acc: 0.0000e+00\n",
      "Epoch 789/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 940.9178 - acc: 0.1145 - val_loss: 1046.6604 - val_acc: 2.4414e-04\n",
      "Epoch 790/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 837.7587 - acc: 0.0791 - val_loss: 1013.7576 - val_acc: 4.8828e-04\n",
      "Epoch 791/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1115.4463 - acc: 0.0983 - val_loss: 1026.3594 - val_acc: 0.2507\n",
      "Epoch 792/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1009.2214 - acc: 0.1152 - val_loss: 977.5832 - val_acc: 0.0000e+00\n",
      "Epoch 793/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1010.3787 - acc: 0.0820 - val_loss: 1023.7751 - val_acc: 0.2498\n",
      "Epoch 794/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 904.0170 - acc: 0.1049 - val_loss: 1137.6757 - val_acc: 2.4414e-04\n",
      "Epoch 795/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1046.1087 - acc: 0.1149 - val_loss: 607.1012 - val_acc: 0.0090\n",
      "Epoch 796/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 948.0295 - acc: 0.1170 - val_loss: 891.1847 - val_acc: 0.0000e+00\n",
      "Epoch 797/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1053.9332 - acc: 0.0819 - val_loss: 852.1315 - val_acc: 0.0000e+00\n",
      "Epoch 798/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 888.6571 - acc: 0.1018 - val_loss: 1044.1526 - val_acc: 0.0000e+00\n",
      "Epoch 799/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 858.1492 - acc: 0.1109 - val_loss: 687.6180 - val_acc: 0.0000e+00\n",
      "Epoch 800/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 955.6131 - acc: 0.0803 - val_loss: 1049.0997 - val_acc: 4.8828e-04\n",
      "Epoch 801/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 962.3729 - acc: 0.0896 - val_loss: 745.3651 - val_acc: 0.0039\n",
      "Epoch 802/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1006.8195 - acc: 0.1332 - val_loss: 1232.0497 - val_acc: 0.0000e+00\n",
      "Epoch 803/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1103.0584 - acc: 0.0847 - val_loss: 879.4557 - val_acc: 7.3242e-04\n",
      "Epoch 804/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1085.7311 - acc: 0.1213 - val_loss: 1276.4460 - val_acc: 0.0000e+00\n",
      "Epoch 805/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1262.7783 - acc: 0.0806 - val_loss: 898.1640 - val_acc: 0.0000e+00\n",
      "Epoch 806/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 859.3979 - acc: 0.0803 - val_loss: 1066.4655 - val_acc: 0.7356\n",
      "Epoch 807/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 861.8696 - acc: 0.1200 - val_loss: 1051.9857 - val_acc: 4.8828e-04\n",
      "Epoch 808/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1010.9811 - acc: 0.0839 - val_loss: 1001.8163 - val_acc: 0.7429\n",
      "Epoch 809/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 913.1240 - acc: 0.1173 - val_loss: 1122.6392 - val_acc: 0.0042\n",
      "Epoch 810/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 937.4569 - acc: 0.1115 - val_loss: 1004.8307 - val_acc: 0.0000e+00\n",
      "Epoch 811/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1023.1313 - acc: 0.0794 - val_loss: 928.0782 - val_acc: 9.7656e-04\n",
      "Epoch 812/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1048.6087 - acc: 0.0978 - val_loss: 1261.9100 - val_acc: 0.2505\n",
      "Epoch 813/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1026.1968 - acc: 0.0909 - val_loss: 621.0185 - val_acc: 0.7324\n",
      "Epoch 814/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 965.2702 - acc: 0.1092 - val_loss: 1066.1220 - val_acc: 0.0029\n",
      "Epoch 815/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1155.3742 - acc: 0.0791 - val_loss: 1201.9914 - val_acc: 0.2495\n",
      "Epoch 816/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 970.0842 - acc: 0.1202 - val_loss: 723.9439 - val_acc: 0.0029\n",
      "Epoch 817/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 748.7339 - acc: 0.1085 - val_loss: 936.7459 - val_acc: 0.0000e+00\n",
      "Epoch 818/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1083.6632 - acc: 0.0794 - val_loss: 1344.6737 - val_acc: 7.3242e-04\n",
      "Epoch 819/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1155.8976 - acc: 0.1255 - val_loss: 897.8113 - val_acc: 9.7656e-04\n",
      "Epoch 820/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 922.9007 - acc: 0.1026 - val_loss: 656.9565 - val_acc: 0.0020\n",
      "Epoch 821/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 912.1599 - acc: 0.0728 - val_loss: 978.7784 - val_acc: 0.2490\n",
      "Epoch 822/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 969.3160 - acc: 0.0897 - val_loss: 993.1045 - val_acc: 0.0000e+00\n",
      "Epoch 823/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 854.8190 - acc: 0.0898 - val_loss: 971.8878 - val_acc: 0.7458\n",
      "Epoch 824/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1061.1889 - acc: 0.1116 - val_loss: 1056.2861 - val_acc: 0.0613\n",
      "Epoch 825/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1170.1426 - acc: 0.0868 - val_loss: 1618.7360 - val_acc: 4.8828e-04\n",
      "Epoch 826/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1220.9633 - acc: 0.0802 - val_loss: 968.5669 - val_acc: 0.0000e+00\n",
      "Epoch 827/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1040.0127 - acc: 0.1070 - val_loss: 1157.9339 - val_acc: 0.0000e+00\n",
      "Epoch 828/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1145.3164 - acc: 0.0903 - val_loss: 905.9826 - val_acc: 0.7383\n",
      "Epoch 829/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 938.6188 - acc: 0.1122 - val_loss: 1285.7662 - val_acc: 0.2490\n",
      "Epoch 830/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 980.8930 - acc: 0.0913 - val_loss: 1080.1748 - val_acc: 4.8828e-04\n",
      "Epoch 831/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1007.1716 - acc: 0.1136 - val_loss: 1019.0810 - val_acc: 0.0000e+00\n",
      "Epoch 832/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1245.2322 - acc: 0.0832 - val_loss: 1049.6485 - val_acc: 0.2488\n",
      "Epoch 833/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1043.4140 - acc: 0.1457 - val_loss: 874.1907 - val_acc: 0.0000e+00\n",
      "Epoch 834/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 4us/sample - loss: 934.3708 - acc: 0.0708 - val_loss: 1344.7292 - val_acc: 4.8828e-04\n",
      "Epoch 835/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1322.1608 - acc: 0.0925 - val_loss: 1197.4531 - val_acc: 0.0000e+00\n",
      "Epoch 836/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 942.4905 - acc: 0.0965 - val_loss: 733.7865 - val_acc: 0.0000e+00\n",
      "Epoch 837/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 991.6653 - acc: 0.0950 - val_loss: 1062.5897 - val_acc: 0.0000e+00\n",
      "Epoch 838/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1159.4300 - acc: 0.1020 - val_loss: 1136.0800 - val_acc: 0.0000e+00\n",
      "Epoch 839/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1020.7983 - acc: 0.0776 - val_loss: 1078.5129 - val_acc: 0.0000e+00\n",
      "Epoch 840/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1115.4138 - acc: 0.1253 - val_loss: 1278.1889 - val_acc: 0.0000e+00\n",
      "Epoch 841/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1204.1723 - acc: 0.0829 - val_loss: 1677.6952 - val_acc: 0.0000e+00\n",
      "Epoch 842/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1319.5831 - acc: 0.0959 - val_loss: 1141.9495 - val_acc: 0.7202\n",
      "Epoch 843/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 969.9918 - acc: 0.1120 - val_loss: 852.6467 - val_acc: 0.0000e+00\n",
      "Epoch 844/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1017.7488 - acc: 0.1078 - val_loss: 1228.9518 - val_acc: 0.0000e+00\n",
      "Epoch 845/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1201.8985 - acc: 0.0904 - val_loss: 1165.8700 - val_acc: 0.0020\n",
      "Epoch 846/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1262.3750 - acc: 0.1021 - val_loss: 1411.9593 - val_acc: 0.7449\n",
      "Epoch 847/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1413.6131 - acc: 0.1078 - val_loss: 1086.0073 - val_acc: 2.4414e-04\n",
      "Epoch 848/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1010.6509 - acc: 0.0918 - val_loss: 918.8663 - val_acc: 0.0000e+00\n",
      "Epoch 849/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1202.0700 - acc: 0.0800 - val_loss: 1014.9902 - val_acc: 0.0000e+00\n",
      "Epoch 850/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1110.7527 - acc: 0.1144 - val_loss: 1246.7194 - val_acc: 0.0049\n",
      "Epoch 851/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1146.1066 - acc: 0.1297 - val_loss: 1270.1252 - val_acc: 0.0000e+00\n",
      "Epoch 852/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1061.5156 - acc: 0.0825 - val_loss: 1511.1281 - val_acc: 0.0015\n",
      "Epoch 853/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1295.4997 - acc: 0.0812 - val_loss: 1082.5363 - val_acc: 0.7388\n",
      "Epoch 854/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1050.0463 - acc: 0.1142 - val_loss: 1149.3470 - val_acc: 9.7656e-04\n",
      "Epoch 855/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1067.1402 - acc: 0.0968 - val_loss: 1286.6163 - val_acc: 0.0271\n",
      "Epoch 856/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1063.2946 - acc: 0.1024 - val_loss: 1120.0363 - val_acc: 9.7656e-04\n",
      "Epoch 857/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1169.2604 - acc: 0.0801 - val_loss: 1244.9272 - val_acc: 4.8828e-04\n",
      "Epoch 858/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1239.5124 - acc: 0.1014 - val_loss: 1505.7932 - val_acc: 0.7144\n",
      "Epoch 859/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1345.4587 - acc: 0.1182 - val_loss: 1296.6843 - val_acc: 2.4414e-04\n",
      "Epoch 860/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1151.5695 - acc: 0.0833 - val_loss: 1072.8430 - val_acc: 0.0022\n",
      "Epoch 861/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1296.7175 - acc: 0.1119 - val_loss: 1156.5570 - val_acc: 0.0000e+00\n",
      "Epoch 862/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1315.7268 - acc: 0.0891 - val_loss: 1559.5470 - val_acc: 0.0000e+00\n",
      "Epoch 863/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1295.7623 - acc: 0.1166 - val_loss: 1186.0013 - val_acc: 0.0015\n",
      "Epoch 864/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1241.4719 - acc: 0.0870 - val_loss: 1133.7093 - val_acc: 0.0015\n",
      "Epoch 865/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1211.5717 - acc: 0.1065 - val_loss: 1422.1537 - val_acc: 0.0000e+00\n",
      "Epoch 866/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1191.5265 - acc: 0.0856 - val_loss: 1266.0467 - val_acc: 0.7336\n",
      "Epoch 867/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1051.5721 - acc: 0.1196 - val_loss: 1002.2923 - val_acc: 2.4414e-04\n",
      "Epoch 868/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 908.9684 - acc: 0.1289 - val_loss: 1042.9898 - val_acc: 4.8828e-04\n",
      "Epoch 869/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 967.7408 - acc: 0.0848 - val_loss: 1223.1687 - val_acc: 0.0000e+00\n",
      "Epoch 870/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1064.1800 - acc: 0.0752 - val_loss: 1286.2888 - val_acc: 0.2495\n",
      "Epoch 871/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 998.1188 - acc: 0.1251 - val_loss: 845.2732 - val_acc: 4.8828e-04\n",
      "Epoch 872/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1193.1079 - acc: 0.0742 - val_loss: 1191.3267 - val_acc: 4.8828e-04\n",
      "Epoch 873/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1111.3214 - acc: 0.1210 - val_loss: 1293.0600 - val_acc: 0.0000e+00\n",
      "Epoch 874/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1228.6406 - acc: 0.0807 - val_loss: 1150.3411 - val_acc: 0.2490\n",
      "Epoch 875/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1285.2024 - acc: 0.0848 - val_loss: 912.5449 - val_acc: 0.0000e+00\n",
      "Epoch 876/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1048.1211 - acc: 0.1116 - val_loss: 983.8861 - val_acc: 2.4414e-04\n",
      "Epoch 877/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1149.2584 - acc: 0.0820 - val_loss: 1199.9785 - val_acc: 0.7249\n",
      "Epoch 878/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1207.5979 - acc: 0.1227 - val_loss: 1042.5803 - val_acc: 0.2498\n",
      "Epoch 879/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1167.0960 - acc: 0.0969 - val_loss: 1269.6098 - val_acc: 0.0000e+00\n",
      "Epoch 880/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1416.7914 - acc: 0.1415 - val_loss: 1145.1149 - val_acc: 0.0000e+00\n",
      "Epoch 881/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1413.0156 - acc: 0.0844 - val_loss: 1663.7175 - val_acc: 0.2493\n",
      "Epoch 882/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1146.3314 - acc: 0.0890 - val_loss: 935.2411 - val_acc: 2.4414e-04\n",
      "Epoch 883/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1299.5441 - acc: 0.0991 - val_loss: 1484.0086 - val_acc: 0.7214\n",
      "Epoch 884/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1348.8767 - acc: 0.0820 - val_loss: 1262.9542 - val_acc: 4.8828e-04\n",
      "Epoch 885/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1136.2588 - acc: 0.1240 - val_loss: 1338.8941 - val_acc: 0.0000e+00\n",
      "Epoch 886/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1418.4230 - acc: 0.0908 - val_loss: 1105.9065 - val_acc: 2.4414e-04\n",
      "Epoch 887/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1169.9535 - acc: 0.1306 - val_loss: 1000.3758 - val_acc: 0.0000e+00\n",
      "Epoch 888/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1255.8018 - acc: 0.0843 - val_loss: 1444.6715 - val_acc: 2.4414e-04\n",
      "Epoch 889/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1136.3952 - acc: 0.0785 - val_loss: 935.3826 - val_acc: 9.7656e-04\n",
      "Epoch 890/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1172.1169 - acc: 0.1260 - val_loss: 1544.0557 - val_acc: 0.0000e+00\n",
      "Epoch 891/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1159.9742 - acc: 0.0791 - val_loss: 1164.2934 - val_acc: 0.2488\n",
      "Epoch 892/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1140.2260 - acc: 0.1090 - val_loss: 1128.5111 - val_acc: 4.8828e-04\n",
      "Epoch 893/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1212.6098 - acc: 0.1266 - val_loss: 1396.1348 - val_acc: 0.0000e+00\n",
      "Epoch 894/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1329.6002 - acc: 0.0820 - val_loss: 1472.0161 - val_acc: 0.0000e+00\n",
      "Epoch 895/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1203.4362 - acc: 0.0711 - val_loss: 1004.1385 - val_acc: 7.3242e-04\n",
      "Epoch 896/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1253.2075 - acc: 0.1349 - val_loss: 1026.8243 - val_acc: 0.0000e+00\n",
      "Epoch 897/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1099.7461 - acc: 0.0809 - val_loss: 938.4488 - val_acc: 2.4414e-04\n",
      "Epoch 898/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1465.9249 - acc: 0.1051 - val_loss: 992.1078 - val_acc: 4.8828e-04\n",
      "Epoch 899/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1147.7814 - acc: 0.1104 - val_loss: 1129.2042 - val_acc: 0.0000e+00\n",
      "Epoch 900/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1071.2039 - acc: 0.1196 - val_loss: 1144.5587 - val_acc: 2.4414e-04\n",
      "Epoch 901/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1406.2858 - acc: 0.0886 - val_loss: 1123.3334 - val_acc: 9.7656e-04\n",
      "Epoch 902/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1192.0367 - acc: 0.0801 - val_loss: 896.0426 - val_acc: 0.0000e+00\n",
      "Epoch 903/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1251.8525 - acc: 0.0884 - val_loss: 1328.6248 - val_acc: 0.0000e+00\n",
      "Epoch 904/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1373.9123 - acc: 0.1121 - val_loss: 1261.0964 - val_acc: 4.8828e-04\n",
      "Epoch 905/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1220.8682 - acc: 0.0914 - val_loss: 1022.2013 - val_acc: 4.8828e-04\n",
      "Epoch 906/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1225.7563 - acc: 0.0965 - val_loss: 953.0596 - val_acc: 2.4414e-04\n",
      "Epoch 907/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1110.2937 - acc: 0.0820 - val_loss: 1284.6251 - val_acc: 4.8828e-04\n",
      "Epoch 908/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1119.3308 - acc: 0.1190 - val_loss: 912.8885 - val_acc: 0.0017\n",
      "Epoch 909/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1086.7433 - acc: 0.1155 - val_loss: 1370.2756 - val_acc: 4.8828e-04\n",
      "Epoch 910/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1321.6344 - acc: 0.0733 - val_loss: 1399.1789 - val_acc: 0.0000e+00\n",
      "Epoch 911/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1347.7347 - acc: 0.1083 - val_loss: 1332.2943 - val_acc: 0.0000e+00\n",
      "Epoch 912/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1279.2480 - acc: 0.0941 - val_loss: 1438.9942 - val_acc: 0.0000e+00\n",
      "Epoch 913/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1289.4798 - acc: 0.1118 - val_loss: 1392.6931 - val_acc: 0.0000e+00\n",
      "Epoch 914/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1283.8049 - acc: 0.0828 - val_loss: 1057.5172 - val_acc: 0.6497\n",
      "Epoch 915/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1240.5245 - acc: 0.1144 - val_loss: 1421.2136 - val_acc: 0.0000e+00\n",
      "Epoch 916/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1126.3977 - acc: 0.1099 - val_loss: 1283.7221 - val_acc: 0.0000e+00\n",
      "Epoch 917/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1046.2790 - acc: 0.0802 - val_loss: 1349.1249 - val_acc: 2.4414e-04\n",
      "Epoch 918/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1295.8582 - acc: 0.0823 - val_loss: 1039.7212 - val_acc: 0.0159\n",
      "Epoch 919/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1167.5181 - acc: 0.1091 - val_loss: 1095.3135 - val_acc: 0.0000e+00\n",
      "Epoch 920/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1335.6158 - acc: 0.0916 - val_loss: 1370.0589 - val_acc: 0.0000e+00\n",
      "Epoch 921/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1208.7808 - acc: 0.1183 - val_loss: 1478.2612 - val_acc: 0.0015\n",
      "Epoch 922/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1199.8010 - acc: 0.1195 - val_loss: 1391.2793 - val_acc: 0.0000e+00\n",
      "Epoch 923/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1414.2497 - acc: 0.0692 - val_loss: 1394.3257 - val_acc: 4.8828e-04\n",
      "Epoch 924/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1266.1830 - acc: 0.0797 - val_loss: 1349.5374 - val_acc: 4.8828e-04\n",
      "Epoch 925/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1525.6521 - acc: 0.1177 - val_loss: 2221.6408 - val_acc: 0.2490\n",
      "Epoch 926/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1457.4115 - acc: 0.0829 - val_loss: 1549.6258 - val_acc: 0.0000e+00\n",
      "Epoch 927/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1128.6558 - acc: 0.0944 - val_loss: 898.1288 - val_acc: 0.7417\n",
      "Epoch 928/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1021.4050 - acc: 0.1240 - val_loss: 1193.0752 - val_acc: 0.0000e+00\n",
      "Epoch 929/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1134.4029 - acc: 0.0777 - val_loss: 1155.7551 - val_acc: 0.0000e+00\n",
      "Epoch 930/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1399.9766 - acc: 0.0862 - val_loss: 996.5729 - val_acc: 0.0000e+00\n",
      "Epoch 931/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1053.3206 - acc: 0.1281 - val_loss: 840.8183 - val_acc: 0.2495\n",
      "Epoch 932/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1091.2113 - acc: 0.0702 - val_loss: 1305.0561 - val_acc: 0.7463\n",
      "Epoch 933/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1544.4814 - acc: 0.0831 - val_loss: 1406.1317 - val_acc: 4.8828e-04\n",
      "Epoch 934/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1485.9662 - acc: 0.1185 - val_loss: 1305.8328 - val_acc: 9.7656e-04\n",
      "Epoch 935/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1313.3233 - acc: 0.0820 - val_loss: 2054.8126 - val_acc: 0.7405\n",
      "Epoch 936/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1599.9091 - acc: 0.1315 - val_loss: 1158.2314 - val_acc: 0.0000e+00\n",
      "Epoch 937/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1326.4697 - acc: 0.1091 - val_loss: 1003.4245 - val_acc: 0.0000e+00\n",
      "Epoch 938/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1303.4258 - acc: 0.0793 - val_loss: 1446.3181 - val_acc: 0.0000e+00\n",
      "Epoch 939/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1343.9827 - acc: 0.1000 - val_loss: 1541.8218 - val_acc: 0.0122\n",
      "Epoch 940/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1559.6967 - acc: 0.1018 - val_loss: 1776.9597 - val_acc: 0.0000e+00\n",
      "Epoch 941/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1760.7112 - acc: 0.0936 - val_loss: 1167.8304 - val_acc: 0.0012\n",
      "Epoch 942/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1630.3526 - acc: 0.1015 - val_loss: 1233.3912 - val_acc: 0.5967\n",
      "Epoch 943/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1397.8028 - acc: 0.0946 - val_loss: 1597.0827 - val_acc: 0.0000e+00\n",
      "Epoch 944/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1437.9417 - acc: 0.0807 - val_loss: 1187.9797 - val_acc: 0.0000e+00\n",
      "Epoch 945/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1371.2624 - acc: 0.0936 - val_loss: 1456.8375 - val_acc: 7.3242e-04\n",
      "Epoch 946/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1294.1431 - acc: 0.1359 - val_loss: 944.3034 - val_acc: 0.0000e+00\n",
      "Epoch 947/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1038.1575 - acc: 0.0945 - val_loss: 1522.1755 - val_acc: 0.0000e+00\n",
      "Epoch 948/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1424.4326 - acc: 0.0810 - val_loss: 1386.7277 - val_acc: 0.0000e+00\n",
      "Epoch 949/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1304.1349 - acc: 0.0934 - val_loss: 1055.0201 - val_acc: 0.2507\n",
      "Epoch 950/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1371.4351 - acc: 0.1319 - val_loss: 1562.7164 - val_acc: 0.0000e+00\n",
      "Epoch 951/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1346.2666 - acc: 0.0776 - val_loss: 1253.0414 - val_acc: 0.0029\n",
      "Epoch 952/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1241.0130 - acc: 0.0943 - val_loss: 1057.3632 - val_acc: 0.0000e+00\n",
      "Epoch 953/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1155.8774 - acc: 0.0835 - val_loss: 985.3070 - val_acc: 7.3242e-04\n",
      "Epoch 954/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1287.5453 - acc: 0.1402 - val_loss: 1754.4749 - val_acc: 0.0000e+00\n",
      "Epoch 955/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1536.5747 - acc: 0.0878 - val_loss: 1703.4574 - val_acc: 0.0000e+00\n",
      "Epoch 956/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1358.4908 - acc: 0.1142 - val_loss: 1246.6576 - val_acc: 0.0081\n",
      "Epoch 957/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1478.2349 - acc: 0.1052 - val_loss: 1322.1870 - val_acc: 0.0000e+00\n",
      "Epoch 958/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1374.4044 - acc: 0.0827 - val_loss: 1240.0362 - val_acc: 0.0000e+00\n",
      "Epoch 959/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1279.2073 - acc: 0.0798 - val_loss: 1578.2193 - val_acc: 0.0000e+00\n",
      "Epoch 960/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1456.5624 - acc: 0.1394 - val_loss: 1194.5052 - val_acc: 4.8828e-04\n",
      "Epoch 961/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1305.2394 - acc: 0.0925 - val_loss: 1602.9310 - val_acc: 0.0000e+00\n",
      "Epoch 962/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1361.6717 - acc: 0.0835 - val_loss: 1454.8298 - val_acc: 0.0000e+00\n",
      "Epoch 963/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1320.0061 - acc: 0.0804 - val_loss: 1521.0927 - val_acc: 0.7385\n",
      "Epoch 964/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1224.4065 - acc: 0.1165 - val_loss: 1059.8242 - val_acc: 0.0020\n",
      "Epoch 965/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1213.4264 - acc: 0.1262 - val_loss: 1532.6195 - val_acc: 0.0000e+00\n",
      "Epoch 966/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1493.3085 - acc: 0.0811 - val_loss: 980.6799 - val_acc: 0.0000e+00\n",
      "Epoch 967/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1303.9060 - acc: 0.1086 - val_loss: 1515.6939 - val_acc: 0.0000e+00\n",
      "Epoch 968/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1399.1790 - acc: 0.0774 - val_loss: 1140.3833 - val_acc: 0.2500\n",
      "Epoch 969/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1448.5297 - acc: 0.1118 - val_loss: 1210.5059 - val_acc: 0.2500\n",
      "Epoch 970/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1331.0973 - acc: 0.1326 - val_loss: 1308.8479 - val_acc: 0.0000e+00\n",
      "Epoch 971/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1413.1007 - acc: 0.0922 - val_loss: 1614.2977 - val_acc: 0.0000e+00\n",
      "Epoch 972/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1301.3285 - acc: 0.0665 - val_loss: 1457.4509 - val_acc: 0.8977\n",
      "Epoch 973/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1690.4186 - acc: 0.1064 - val_loss: 1768.6076 - val_acc: 7.3242e-04\n",
      "Epoch 974/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1637.4567 - acc: 0.0935 - val_loss: 1417.7810 - val_acc: 0.7454\n",
      "Epoch 975/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1311.0600 - acc: 0.1414 - val_loss: 915.0390 - val_acc: 7.3242e-04\n",
      "Epoch 976/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1447.2497 - acc: 0.1009 - val_loss: 1501.0602 - val_acc: 4.8828e-04\n",
      "Epoch 977/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1385.3235 - acc: 0.0825 - val_loss: 1344.6945 - val_acc: 0.0000e+00\n",
      "Epoch 978/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1368.6122 - acc: 0.0941 - val_loss: 1566.5705 - val_acc: 0.0027\n",
      "Epoch 979/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1511.1874 - acc: 0.1175 - val_loss: 1470.0840 - val_acc: 0.0000e+00\n",
      "Epoch 980/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1396.8974 - acc: 0.0724 - val_loss: 1135.0295 - val_acc: 4.8828e-04\n",
      "Epoch 981/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1305.8870 - acc: 0.1110 - val_loss: 1682.4437 - val_acc: 2.4414e-04\n",
      "Epoch 982/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1275.5092 - acc: 0.0776 - val_loss: 1312.5990 - val_acc: 0.0000e+00\n",
      "Epoch 983/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1237.7026 - acc: 0.1127 - val_loss: 1118.6280 - val_acc: 0.0181\n",
      "Epoch 984/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1706.1313 - acc: 0.1020 - val_loss: 1563.5945 - val_acc: 9.7656e-04\n",
      "Epoch 985/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1465.3243 - acc: 0.1082 - val_loss: 1265.9651 - val_acc: 0.0000e+00\n",
      "Epoch 986/1000\n",
      "12286/12286 [==============================] - 0s 5us/sample - loss: 1283.3713 - acc: 0.0819 - val_loss: 1047.2147 - val_acc: 0.0000e+00\n",
      "Epoch 987/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1377.1766 - acc: 0.1250 - val_loss: 1936.4343 - val_acc: 0.0000e+00\n",
      "Epoch 988/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1647.2886 - acc: 0.0953 - val_loss: 1566.7012 - val_acc: 0.0000e+00\n",
      "Epoch 989/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1489.8321 - acc: 0.0814 - val_loss: 1332.3762 - val_acc: 0.0000e+00\n",
      "Epoch 990/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1369.9810 - acc: 0.0838 - val_loss: 1569.0051 - val_acc: 0.9866\n",
      "Epoch 991/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1285.4558 - acc: 0.1222 - val_loss: 1865.5311 - val_acc: 0.0000e+00\n",
      "Epoch 992/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1594.0319 - acc: 0.0864 - val_loss: 1572.2581 - val_acc: 0.9841\n",
      "Epoch 993/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1560.6416 - acc: 0.1086 - val_loss: 1552.8260 - val_acc: 0.0078\n",
      "Epoch 994/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1542.7063 - acc: 0.0729 - val_loss: 1450.0932 - val_acc: 0.2498\n",
      "Epoch 995/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1188.2715 - acc: 0.0900 - val_loss: 1507.8774 - val_acc: 0.0020\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1766.7126 - acc: 0.1083 - val_loss: 1976.6468 - val_acc: 0.0000e+00\n",
      "Epoch 997/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1416.4798 - acc: 0.1117 - val_loss: 1457.2657 - val_acc: 0.2495\n",
      "Epoch 998/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1288.1954 - acc: 0.0868 - val_loss: 1793.6211 - val_acc: 0.0000e+00\n",
      "Epoch 999/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1558.7946 - acc: 0.0823 - val_loss: 1818.2508 - val_acc: 0.7415\n",
      "Epoch 1000/1000\n",
      "12286/12286 [==============================] - 0s 4us/sample - loss: 1363.9800 - acc: 0.1210 - val_loss: 1455.8592 - val_acc: 2.4414e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a312ef390>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=1000, batch_size=500,\n",
    "          validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
